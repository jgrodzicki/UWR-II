{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from enum import Enum\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from typing import Dict, List, NamedTuple, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Author(Enum):\n",
    "    PRUS = 0\n",
    "    SIENKIEWICZ = 1\n",
    "    ORZESZKOWA = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text: str) -> str:\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    text = re.sub(r'\\ +', ' ', text)\n",
    "    return text\n",
    "\n",
    "def load_corpus_list(path: str) -> List[str]:\n",
    "    text = open(path, 'r').read()\n",
    "    preprocessed = preprocess(text)\n",
    "    words = preprocessed.split()\n",
    "    return words\n",
    "\n",
    "def occurence_dict_from_corpus(words: List[str]) -> Dict[str, float]:\n",
    "    unique_words, word_counts = np.unique(words, return_counts=True)\n",
    "    word_counts_perc = word_counts / np.sum(word_counts)\n",
    "    return defaultdict(float, zip(unique_words, word_counts_perc))\n",
    "\n",
    "def create_occurence_dicts() -> Dict[Author, Dict[str, float]]:\n",
    "    occurence_dicts = dict()\n",
    "    occurence_dicts[Author.PRUS] = occurence_dict_from_corpus(\n",
    "        words=load_corpus_list(path='data/korpus_prusa.txt')\n",
    "    )\n",
    "    occurence_dicts[Author.SIENKIEWICZ] = occurence_dict_from_corpus(\n",
    "        words=load_corpus_list(path='data/korpus_sienkiewicza.txt')\n",
    "    )\n",
    "    occurence_dicts[Author.ORZESZKOWA] = occurence_dict_from_corpus(\n",
    "        words=load_corpus_list(path='data/korpus_orzeszkowej.txt')\n",
    "    )\n",
    "    return occurence_dicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 1. (3+1+Xp) \n",
    "Napisz program, który ustala autora zdania. Autorów jest trójka: Prus, Orzeszkowa, Sienkiewicz (POS), na SKOSie znajdziesz odpowiednie dane uczące. Powinieneś je podzielić na część uczącą i walidacyjną. Część X punktacji zależeć będzie od tego, jak Twój program wypadnie na tle innych programów dla danych testowych (które pojawią się później na SKOSie). Dwie podstawowe metody są następujące:\n",
    "\n",
    "a) Naive Bayes (będzie na wykładzie 4, powinieneś użyć przynajmniej jednej cechy, która nie jest słowem)\n",
    "\n",
    "b) Utworzenie trzech modeli językowych i wybór tego, który daje najepszy wynik na klasyfikowanym zdaniu.\n",
    "\n",
    "Za sprawdzenie dwóch podejść jest punkt premiowy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_author(text: str, occurence_dicts: Dict[Author, Dict[str, float]]) -> Author:\n",
    "    scores: List[float] = []\n",
    "    for author, occurence_dict in occurence_dicts.items():\n",
    "        words = preprocess(text=text).split()\n",
    "        score = np.sum(np.log([occurence_dict[word] + 1e-5 for word in words]))\n",
    "        scores.append(score)\n",
    "        \n",
    "    author = list(occurence_dicts.keys())[np.argmax(scores)]\n",
    "    return author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classifier(folder_path: str) -> np.ndarray:\n",
    "    '''\n",
    "    Returns confussion matrix\n",
    "    '''\n",
    "    occurence_dicts = create_occurence_dicts()\n",
    "    \n",
    "    authors_number = len(list(occurence_dicts.keys()))\n",
    "    confussion_matrix = np.zeros((authors_number, authors_number))\n",
    "    \n",
    "    for relative_path in os.listdir(folder_path):\n",
    "        path = os.path.join(folder_path, relative_path)\n",
    "        \n",
    "        if not os.path.isfile(path):\n",
    "            continue\n",
    "        \n",
    "        true_author: Optional[Author] = None\n",
    "        \n",
    "        if 'orzeszkowej' in relative_path:\n",
    "            true_author = Author.ORZESZKOWA\n",
    "        if 'prusa' in relative_path:\n",
    "            true_author = Author.PRUS\n",
    "        if 'sienkiewicza' in relative_path:\n",
    "            true_author = Author.SIENKIEWICZ\n",
    "        \n",
    "        if true_author is None:\n",
    "            print(f'Could not find a true author of the text! Filename: {relative_path}')\n",
    "            continue\n",
    "        \n",
    "        text = open(path, 'r').read()\n",
    "        classified_author = find_author(text=text, occurence_dicts=occurence_dicts)\n",
    "        \n",
    "        confussion_matrix[true_author.value, classified_author.value] += 1\n",
    "    \n",
    "    return confussion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['PRUS', 'SIENKIEWICZ', 'ORZESZKOWA'],\n",
       " array([[21.,  0.,  0.],\n",
       "        [15., 12.,  0.],\n",
       "        [ 0.,  0., 12.]]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confussion_matrix = test_classifier(folder_path='testy1')\n",
    "authors = list(map(lambda author: author.name, list(Author)))\n",
    "authors, confussion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 2. (3+Xp) \n",
    "W zadaniu tym powinieneś uporządkować (spermutować) ciąg słów, żeby utworzył zdanie. W stosunku do poprzedniej listy mamy następujące różnice:\n",
    "\n",
    "a) powinieneś wykorzystać tagi słów (na przykład z pliku supertags.txt, link na SKOSie)\n",
    "\n",
    "b) powinieneś je połączyć ze zwykłymi statystykami bigramowymi (lub, opcjonalnie, z sufiksami)\n",
    "\n",
    "c) powinieneś wyodrębnić z danych uczących część walidacyjną i dobrać parametry łączenia modeli bazujących na słowach i bazujących na tagach.\n",
    "\n",
    "Sposób oceny będzie taki sam, jak w przypadku zadania z P1. Wybór zdań do oceny pojawi się przed zajęciami (będą to zdania zawierające od 4 do 8 tokenów, wybrane losowo z części testowej korpusu PolEval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 3. (4p) \n",
    "W zadaniu tym powinieneś losować zdania o słowach z identyczną charakterystyką gramatyczną jak zdanie wejściowe). Przykładowo dla zdania:\n",
    "\n",
    "Mały Piotruś spotkał w niewielkiej restauracyjce wczoraj poznaną koleżankę. wynikiem mogłoby być\n",
    "Gruby Stefan przeczytał we wczorajszej gazecie starannie przygotowaną analizę.\n",
    "Zgodność gramatyczną sprawdzamy za pomocą tagów z pliku supertags. Przyjmijmy, że słowo s niewystępujące w tym pliku ma opis gramatyczny (’^’ + s)[-3:]. Powinieneś korzystać ze statystyk unigramowych."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 4. (3p) \n",
    "Dodaj statystyki bigramowe do powyższego zadania. Postaraj się, by jak najrza- dziej zdażały się sytuacje, w których musisz losować posługując się unigramami. Zaznaczaj znakiem \"|\" każdą taką nieciągłość."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 5. (5+1p) \n",
    "W zadaniu tym zajmiemy się kolokacjami słów, o których mamy informacje gramatyczną. Napisz program, który dla danego słowa znajduje k najbardziej z nim „spokrewnio- nych” słów. Rozważ następujące metody wyznaczania kolokacji:\n",
    "\n",
    "a) PPMI (Positive Pointwise Mutual Information)\n",
    "\n",
    "b) jakiś inny, dowolnie wybrany, z używanych na kolokacje wzorów (więcej na wykładzie),\n",
    "\n",
    "c) kolokacje gramatyczno-słowowe (tzn. żeby dwa słowa były uznane za kolokacje, warunek kolo- kacyjności (dowolnie wybrany) powinny spełniać zarówno tagi słów, jak i same słowa.\n",
    "\n",
    "d) jakaś dowolna inna metoda, lub Twoja modyfikacja powyższych (za to dodatkowy punkt).\n",
    "\n",
    "Możesz się ograniczyć do słów, które są stosunkowo częste (więcej niż n wystąpień w korpusie) i występują co najmniej raz w jakimś trigramie (lub k razy w jakimś bigramie). Wybierz niewielki zbiór słów (powiedzmy koło 10). Przygotuj raport, w którym dla każdego z tych słów jest 10 najbardziej spokrewnionych słow (czyli takich, o największym współczynniku kolokacji), dla różnych metod wyznaczania kolokacji."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 6. (7p) \n",
    "W zadaniu tym będziemy tworzyć pierwszą wersję programu tworzącego poezję (przypominającą Pana Tadeusza, oznaczanego dalej PT)). Przypomnijmy najważniejsze fakty od- noszące się do tego utworu (i ogólnie Poezji):\n",
    "\n",
    "F1. Wiersz składa się z wersetów, z których każdy ma ustaloną liczbę sylab (w PT to 13)\n",
    "\n",
    "F2. Ostatnie słowo w wersecie n rymuje się z ostatnim słowem w wersecie n + 1 (dla n parzystego,\n",
    "numeracja od 0).\n",
    "\n",
    "F3. Rym to zgodność ostatniej sylaby i części od samogłoski sylaby przedostatniej (zdrowie-dowie). W zasadzie rymy to zjawisko fonetyczne, ale dla języka polskiego (w pierwszej wersji) można sobie to trochę uprościć i powiedzieć, że dotyczą one liter.\n",
    "\n",
    "F4. Akcenty słów i podziały słów muszą się jakoś sensownie układać. Nam wystarczy przyjąć, że godzimy się jedynie na takie podziały wersu na słowa k-sylabowe3, których użył Adam Mickiewicz, na przykład:\n",
    "\n",
    "Litwo, Ojczyzno moja, Ty jesteś jak zdrowie, ile cię trzeba cenić, ten tylko się dowie ma schemat: [2,3,2,1,2,1,2] -- [2,1,2,2,1,2,1,2]\n",
    "\n",
    "F5. Podział na sylaby nie jest trywialny (dlaczego?). Ale na nasze szczęście policzenie sylab jest łatwe. Słowo ma tyle sylab, ile ma samogłosek (przy czym połączenia ie, iu, ię, itd traktujemy jako jedną samogłoskę). Część rymowana wyrazu to część wyrazu od przedostatniej samogłoski do końca.\n",
    "\n",
    "Powinieneś stworzyć program, generujący dwuwersowe fragmenty wierszy w stylu PT, czyli powinieneś przypilnować:\n",
    "\n",
    "a) żeby wersy były poprawne rytmicznie i się rymowały,\n",
    "\n",
    "b) żeby dwuwers miał sens gramatyczny (czyli by tagi słów pasowały do jakiegoś zdania lub frag- mentu zdania)\n",
    "\n",
    "c) żeby były jakoś wykorzystane statystyki N-gramowe (plan minimum to statystyki 1-gramowe, dodatkowe +1 za wykorzystanie bigramów)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 7. (5p) \n",
    "Zmodyfikuj algorytm z poprzedniego zadania w ten sposób, by starał się on maksymalizować wzajemną „kolokacyjność” słów z dwuwersu (tak, by jak najwięcej słów było ze sobą powiązanych, na przykład przez wysokie PPMI). Akceptowalna jest dowolna procedura (local search, jakieś błądzenie losowe, metody ewolucyjne, ...), która daje wartość liczby par słów będących kolokacjami istotnie większą niż losowanie z poprzedniego zadania.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
