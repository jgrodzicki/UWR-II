{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from tqdm import tqdm, trange\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "from itertools import permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ngrams_consisting_words_and_create_mapping(filename, words_in_sentences, n):\n",
    "    mapping = defaultdict(set)\n",
    "    mapping_count = defaultdict(int)\n",
    "    \n",
    "    total = 0\n",
    "    if n == 2:\n",
    "        total = 59134225\n",
    "    elif n == 3:\n",
    "        total = 179473348\n",
    "    pbar = tqdm(desc='Creating successor mapping', total=total)\n",
    "    with open(filename, 'r') as f:\n",
    "        row = f.readline().lower().strip()\n",
    "        \n",
    "        while row:\n",
    "            pbar.update(1)\n",
    "            if type(row) is str:\n",
    "                row = row.split()\n",
    "            \n",
    "            cnt = int(row[0])\n",
    "            words = row[1:-1]\n",
    "            rest = row[-1]\n",
    "            \n",
    "            if cnt < 2:\n",
    "                row = f.readline().lower().strip()\n",
    "                continue\n",
    "            \n",
    "            if all([sent_word not in words for sent_word in words_in_sentences]):\n",
    "                row = f.readline().lower().strip()\n",
    "                continue\n",
    "            \n",
    "            if len(words) == 1:\n",
    "                words = words[0]\n",
    "            else:\n",
    "                words = tuple(words)\n",
    "            \n",
    "            mapping[words].add(rest)\n",
    "            mapping_count[(words, rest)] += cnt\n",
    "            \n",
    "            row = f.readline().lower().strip()\n",
    "    pbar.close()\n",
    "    return mapping, mapping_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_input():\n",
    "    return open('data/input_task4.txt', 'r').read().lower().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_naturalness_bigram(sentence, mapping, mapping_count):\n",
    "    \"\"\"\n",
    "    Being sum of occurrences of sequences of words in the mapping.\n",
    "    \"\"\"\n",
    "    prev_word = sentence[0]\n",
    "    \n",
    "    naturalness = 0\n",
    "    \n",
    "    for word in sentence[1:]:\n",
    "        occurences = mapping_count[(prev_word, word)]\n",
    "        naturalness += occurences\n",
    "        prev_word = word\n",
    "        \n",
    "    return naturalness\n",
    "\n",
    "\n",
    "def compute_naturalness_trigram(sentence, mapping, mapping_count):\n",
    "    \"\"\"\n",
    "    Being sum of occurrences of sequences of words in the mapping.\n",
    "    \"\"\"\n",
    "    prev_word = tuple(sentence[:2])\n",
    "    \n",
    "    naturalness = 0\n",
    "    \n",
    "    for word in sentence[2:]:\n",
    "        occurences = mapping_count[(prev_word, word)]\n",
    "        naturalness += occurences\n",
    "        prev_word = prev_word[1:] + tuple(word)\n",
    "        \n",
    "    return naturalness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_sentence(words, mapping, mapping_count, compute_naturalness_func):\n",
    "    possible_sentences = np.array(list(permutations(words)))\n",
    "    possible_naturalness = np.array(\n",
    "        list(map(\n",
    "            lambda sent: \n",
    "                compute_naturalness_func(\n",
    "                    sentence=sent, \n",
    "                    mapping=mapping, \n",
    "                    mapping_count=mapping_count,), \n",
    "            possible_sentences))\n",
    "    )\n",
    "    \n",
    "    ordering = np.argsort(possible_naturalness)[::-1]\n",
    "    \n",
    "    return possible_sentences[ordering], possible_naturalness[ordering]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = load_input()\n",
    "words_in_sentences = set(' '.join(sentences).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating successor mapping: 100%|█████████▉| 59134224/59134225 [08:08<00:00, 121069.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: 0.2547829169450466\n",
      "good ones: 14\n"
     ]
    }
   ],
   "source": [
    "bigram_mapping, bigram_mapping_count = load_ngrams_consisting_words_and_create_mapping('data/poleval_2grams.txt', words_in_sentences, 2)\n",
    "\n",
    "positions = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    sentence = sentence.strip()\n",
    "    words = sentence.split()\n",
    "    possible_sentences, possible_naturalness = reconstruct_sentence(\n",
    "        words=words, \n",
    "        mapping=bigram_mapping, \n",
    "        mapping_count=bigram_mapping_count,\n",
    "        compute_naturalness_func=compute_naturalness_bigram,\n",
    "    )\n",
    "    possible_sentences = list(map(lambda words: ' '.join(words), possible_sentences))\n",
    "    position = np.nonzero(np.array(possible_sentences) == sentence)[0][0]\n",
    "    positions.append(position)\n",
    "    # print_results(sentence, possible_sentences, possible_naturalness)\n",
    "print(f'result: {np.mean(1 / (np.array(positions)+1))}\\ngood ones: {np.count_nonzero(np.array(positions) == 0)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating successor mapping: 100%|██████████| 179473348/179473348 [41:33<00:00, 71981.44it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: 0.0957230449955125\n",
      "good ones: 5\n"
     ]
    }
   ],
   "source": [
    "trigram_mapping, trigram_mapping_count = load_ngrams_consisting_words_and_create_mapping('data/poleval_3grams.txt', words_in_sentences, 3)\n",
    "    \n",
    "positions = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    sentence = sentence.strip()\n",
    "    words = sentence.split()\n",
    "    possible_sentences, possible_naturalness = reconstruct_sentence(\n",
    "        words=words,\n",
    "        mapping=trigram_mapping, \n",
    "        mapping_count=trigram_mapping_count,\n",
    "        compute_naturalness_func=compute_naturalness_trigram,\n",
    "    )\n",
    "    # print_results(sentence, possible_sentences, possible_naturalness)\n",
    "    possible_sentences = list(map(lambda words: ' '.join(words), possible_sentences))\n",
    "    position = np.nonzero(np.array(possible_sentences) == sentence)[0][0]\n",
    "    positions.append(position)\n",
    "print(f'result: {np.mean(1 / (np.array(positions) + 1))}\\ngood ones: {np.count_nonzero(np.array(positions) == 0)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
