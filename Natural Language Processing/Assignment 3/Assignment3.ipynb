{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import re\n",
    "from typing import Tuple, DefaultDict, Dict, List, Optional\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 1. (5p) \n",
    "W zadaniu tym masz napisać system, który bierze na wejściu (ztokenizowany) tekst w języku polskim, pozbawiony wielkich liter oraz polskich znaków diakrytycznych i wypisuje na wyjściu poprawny tekst w języku polskim. Zakładamy, że literka „ź” na wejściu jest reprezentowana przez „z” (a nie „x”). Liczymy dwie miary dokładności:\n",
    "\n",
    "a) Dokładność polskawa, czyli liczba słów poprawnie zrekonstruowanych (modulo wielkość liter, której nie uwzględniamy w tej mierze) podzielona przez liczbę słów w ogóle\n",
    "\n",
    "b) Dokładność pełna, czyli liczba słów poprawnie zrekonstruowanych podzielona przez liczbę słów (tu uwzględniamy zarówno ogonki jak i wielkość liter).\n",
    "\n",
    "Ostatecznym wynikiem będzie średnia geometryczna tych liczb. W tym zadaniu sprawdzany jest poziom basic, to znaczy że prezentowane rozwiązanie powinno:\n",
    "- rekonstruować stokenizowany tekst,\n",
    "- wykorzystywać dane dotyczące unigramów z części uczącej korpusu,\n",
    "- w jakiś sposób (dowolny sensowny) uwzględniać informacje o dłuższych ciągach słów.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000000/1000000 [00:21<00:00, 47372.26it/s]\n"
     ]
    }
   ],
   "source": [
    "corpus_count = defaultdict(int)\n",
    "with open('data.nogit/polish_corpora.txt', 'r') as f:\n",
    "    for _ in trange(1000000):\n",
    "        row = f.readline()\n",
    "        text = preprocess(row)\n",
    "        for w in text.split():\n",
    "            corpus_count[w] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text: str) -> str:\n",
    "    text = re.sub('[^a-zA-ZęóąśłżźńĘÓĄŚŁŻŹŃ ]', '', text)\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text: str) -> str:\n",
    "    polish_chars_replacements = {'ę': 'e', 'ó': 'o', 'ą': 'a', 'ś': 's', 'ł': 'l', 'ż': 'z', 'ź': 'z', 'ń': 'n'}\n",
    "    text = text.lower()\n",
    "    for polish, replacement in polish_chars_replacements.items():\n",
    "        text = text.replace(polish, replacement)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_norm_bigrams = np.min(list(bigrams_count.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_text(\n",
    "    original: str, \n",
    "    corpora_counts: DefaultDict[str, int], \n",
    "    bigrams: DefaultDict[str, List[str]],\n",
    "    bigram_count: DefaultDict[Tuple[str, str], float],\n",
    "    tokenized_to_word_mapping: Dict[str, str],\n",
    ") -> str:\n",
    "    assert len(original) > 0\n",
    "    reconstructed_words = []\n",
    "    tokenized = tokenize(original)\n",
    "    prev_word = None\n",
    "    for tokenized_word in tokenized.split():\n",
    "        word = reconstruct_word(prev_word, tokenized_word, corpora_counts, bigrams, bigram_count, tokenized_to_word_mapping)\n",
    "        reconstructed_words.append(word)\n",
    "        prev_word = tokenized_word\n",
    "        \n",
    "    # Start with a big letter\n",
    "    first_word_list = list(reconstructed_words[0])\n",
    "    first_word_list[0] = first_word_list[0].upper()\n",
    "    reconstructed_words[0] = ''.join(first_word_list)\n",
    "    return ' '.join(reconstructed_words)\n",
    "\n",
    "alpha = 0.5\n",
    "def reconstruct_word(\n",
    "    prev_word: Optional[str],\n",
    "    tokenized_word: str, \n",
    "    corpora_counts: DefaultDict[str, int], \n",
    "    bigrams: DefaultDict[str, List[str]],\n",
    "    bigram_count: DefaultDict[Tuple[str, str], float],\n",
    "    tokenized_to_word_mapping: DefaultDict[str, List[str]],\n",
    ") -> str:\n",
    "    if tokenized_word not in tokenized_to_word_mapping:\n",
    "        return tokenized_word\n",
    "    possible_words = tokenized_to_word_mapping[tokenized_word]\n",
    "    \n",
    "    if prev_word is not None and prev_word in bigrams:\n",
    "        next_words = list(bigrams[prev_word].intersection(set(possible_words)))\n",
    "        if len(next_words) > 0:\n",
    "            probs = [(alpha * bigram_count[prev_word, w] * to_norm_bigrams) **0.75 + \n",
    "                     ((1-alpha) * corpora_counts[w]) ** 0.75 \n",
    "                     for w in next_words]\n",
    "            best_word = next_words[np.argmax(probs)]\n",
    "            return best_word\n",
    "    \n",
    "    probs = [corpora_counts[w] for w in possible_words]\n",
    "    best_word = possible_words[np.argmax(probs)]\n",
    "    return best_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity(original: str, reconstucted: str) -> float:\n",
    "    similarities = [0, 0]\n",
    "    for original_word, recontructed_word in zip(original.split(), reconstucted.split()):\n",
    "        if original_word.lower() == recontructed_word.lower():\n",
    "            similarities[0] += 1\n",
    "            \n",
    "            if original_word == recontructed_word:\n",
    "                similarities[1] += 1\n",
    "    \n",
    "    number_of_words = original.count(' ') + 1\n",
    "    return np.sqrt(np.prod(similarities)) / number_of_words\n",
    "#     return similarities[0] / number_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora_counts = pickle.load(open('data.nogit/corpora_counts.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved = pickle.load(open('bigrams_saved.nogit/saved.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = saved['from_words']['bigrams']\n",
    "bigrams_count = saved['from_words']['bigrams_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2980295/2980295 [01:06<00:00, 45063.15it/s] \n"
     ]
    }
   ],
   "source": [
    "tokenized_to_word_mapping = defaultdict(list)\n",
    "for word in tqdm(corpora_counts.keys()):\n",
    "    tokenized_word = tokenize(word)\n",
    "    tokenized_to_word_mapping[tokenized_word].append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for corpus in ['prusa', 'orzeszkowej', 'sienkiewicza']:\n",
    "    sentences.extend(open(f'data.nogit/korpus_{corpus}.txt', 'r').read().split('\\n'))\n",
    "preprocessed_sentences = list(filter(lambda sent: len(sent) > 0, [preprocess(sent) for sent in sentences]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Antek',\n",
       " 'Antek urodził się we wsi nad Wisłą',\n",
       " 'Wieś leżała w niewielkiej dolinie Od północy otaczały ją wzgórza spadziste porosłe sosnowym lasem a od południa wzgórza garbate zasypane leszczyną tarniną i głogiem Tam najgłośniej śpiewały ptaki i najczęściej chodziły wiejskie dzieci rwa orzechy albo wybiera gniazda',\n",
       " 'Kiedyś stanął na środku wsi zdawało ci się że oba pasma gór biegną ku sobie ażeby zetkną się tam gdzie z rana wstaje czerwone słońce Ale było to złudzenie',\n",
       " 'Za wsią bowiem ciągnęła się między wzgórzami dolina przecięta rzeczułką i przykryta zieloną łąką',\n",
       " 'Tam pasano bydlątka i tam cienkonogie bociany chodziły polowa na żaby kukające wieczorami',\n",
       " 'Od zachodu wieś miała tamę za tamą Wisłę a za Wisłą znowu wzgórza wapienne nagie',\n",
       " 'Każdy chłopski dom szarą słomą pokryty miał ogródek a w ogródku śliwki węgierki spomiędzy których wida było komin sadzą uczerniony i pożarną drabinkę Drabiny te zaprowadzono nie od dawna a ludzie myśleli że one lepiej chroni będą chaty od ognia niż dawniej bocianie gniazda Toteż gdy płonął jaki budynek dziwili się bardzo ale go nie ratowali',\n",
       " 'Wida że na tego gospodarza był dopust boski mówili między sobą Spalił się cho miał przecie nową drabinę i cho zapłacił śtraf za starą co to były u niej połamane szczeble',\n",
       " 'W takiej wsi urodził się Antek Położyli go w niemalowanej kołysce co została po zmarłym bracie i sypiał w niej przez dwa lata Potem przyszła mu na świat siostra Rozalia więc musiał jej miejsca ustąpi a sam jako osoba dorosła przenieś się na ławę']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/17180 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t0.9206766149755737\n",
      "Wieś leżała w niewielkiej dolinie Od północy otaczały ją wzgórza spadziste porosłe sosnowym lasem a od południa wzgórza garbate zasypane leszczyną tarniną i głogiem Tam najgłośniej śpiewały ptaki i najczęściej chodziły wiejskie dzieci rwa orzechy albo wybiera gniazda\n",
      "Wieś leżała w niewielkiej dolinie od północy otaczały ją wzgórza spadziste porosłe sosnowym lasem a od południa wzgórza garbate zasypane leszczyna tarnina i głogiem tam najgłośniej śpiewały ptaki i najczęściej chodziły wiejskie dzieci rwa orzechy albo wybiera gniazda\n",
      "\n",
      "0.9206766149755737 0.9206766149755737 0.9206766149755737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "similarities = []\n",
    "for sentence in tqdm(preprocessed_sentences[2:], position=0, leave=True):\n",
    "    reconstructed_sentence = reconstruct_text(sentence, corpus_count, bigrams, bigrams_count, tokenized_to_word_mapping)\n",
    "    similarity = compute_similarity(original=sentence, reconstucted=reconstructed_sentence)\n",
    "    similarities.append(similarity)\n",
    "    print(f'\\t\\t{similarity}\\n{sentence}\\n{reconstructed_sentence}\\n')\n",
    "    break\n",
    "\n",
    "print(np.min(similarities), np.mean(similarities), np.max(similarities))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 2. (3 + Xp) \n",
    "W tym zadaniu rozwiązać należy dokładnie ten sam problem, co w poprzednim zadaniu. Żeby zadanie było uznane za zrobione poprawnie, wynik Twojego programu (na zbiorze ewaluacyjnym), musi być wyższy niż K = 0.955. Dodatkowo, jeżeli wynik R Twojego programu będzie większy niż Y = 0.96, to za zadanie dostaniesz 4 × $\\frac{R−Y}{1-Y}$ . Dodatkowa premia to 4 punkty za najlepszy program, 3 punkty za drugie miejsce, 2 punkty za trzecie i 1 punkt za czwarte (liczone we wszystkich grupach). Dozwolone jest korzystanie z korpusu PolEval (pierwszy milion wierszy), N-gramów NKJP oraz Morfologika. Zbiór testowy to kolejne 200 tysięcy wierszy korpusu PolEvala."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_validation_set():\n",
    "    i = 0\n",
    "    validation_set = []\n",
    "    with open('data.nogit/polish_corpora.txt', 'r') as f:\n",
    "        while i < 1e6+200000:\n",
    "            row = f.readline()\n",
    "            i += 1\n",
    "            if i < 1e6:\n",
    "                continue\n",
    "            validation_set.append(row)\n",
    "    validation_set = (' '.join(validation_set)).split('.')\n",
    "    return validation_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set = create_validation_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200001/200001 [01:16<00:00, 2623.40it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9106598472302138"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = 0\n",
    "similarities = []\n",
    "for sentence in tqdm(validation_set, position=0, leave=True):\n",
    "    sentence = preprocess(sentence)\n",
    "    if len(sentence) == 0:\n",
    "        continue\n",
    "    reconstructed_sentence = reconstruct_text(sentence, corpora_counts, bigrams, bigrams_count, tokenized_to_word_mapping)\n",
    "    similarity = compute_similarity(original=sentence, reconstucted=reconstructed_sentence)\n",
    "    similarities.append(similarity)\n",
    "#     print(f'\\t\\t{similarity}\\n{sentence}\\n{reconstructed_sentence}\\n')\n",
    "#     break\n",
    "np.mean(similarities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 3. (4p) \n",
    "W zadaniu tym zajmiemy się omawianym na wykładzie ukrytym łańcuchem Markowa, na przykładzie nieuczciwego krupiera rzucającego kością. Przypominam zasady:\n",
    "1. Krupier ma dwie kości, uczciwą i oszukaną.\n",
    "2. Kość oszukana daje 6 oczek z p = 1/2, a pozostałe wyniki z p = 1/10\n",
    "3. Krupier zmienia kość uczciwą na nieuczciwą z p1 = 0.04, a nieuczciwą na uczciwą z p2 = 0.05\n",
    "4. Zaczynamy od uczciwej kości.\n",
    "\n",
    "Napisz program, który dla danego ciągu rzutów (który musisz sam wygenerować) wypisuje ciąg stanów (u – kość uczciwa, n – kość nieuczciwa, długość rzędu 10000), w sposób maksymalizujący liczbę prawidłowo zgadniętych stanów. Rozwiąż to zadanie na dwa sposoby:\n",
    "- Proponując heurystyczny algorytm decydujący na podstawie badania skupisk szóstek\n",
    "- Implementując poprawny algorytm, bazujący na zmiennych α oraz β (zobacz wykład o HMM).\n",
    "\n",
    "Wykonując eksperymenty, oszacuj poprawność działania obu algorytmów, mierzoną liczbą poprawnie zgadniętych stanów (podzieloną przez długość ciągu)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_probs = np.full(6, 1/6)\n",
    "trick_probs = np.append(np.full(5, 1/10), 1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_to_trick_change_prob = 0.04\n",
    "trick_to_valid_change_prob = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_series(length: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    uses_valid = True\n",
    "    dice_series, labels = [], []\n",
    "    for _ in range(length):\n",
    "        labels.append(uses_valid)\n",
    "        if uses_valid:\n",
    "            dice = np.random.choice(6, p=valid_probs) + 1\n",
    "            if np.random.random() < valid_to_trick_change_prob:\n",
    "                uses_valid = False\n",
    "        else:\n",
    "            dice = np.random.choice(6, p=trick_probs) + 1\n",
    "            if np.random.random() < trick_to_valid_change_prob:\n",
    "                uses_valid = True\n",
    "        dice_series.append(dice)\n",
    "    return np.array(dice_series), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 10000\n",
    "dice_series, labels = generate_series(length=length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_labels(dice_series: np.ndarray, min_mean_to_fake: int=0.54) -> np.ndarray:\n",
    "    labels = np.ones_like(dice_series, dtype=bool)\n",
    "    \n",
    "    six_idxs = np.flatnonzero(dice_series == 6)\n",
    "    for i, start_six_idx in tqdm(enumerate(six_idxs), total=len(six_idxs)):\n",
    "        if start_six_idx == 0:\n",
    "            continue\n",
    "        for end_six_idx in six_idxs[i+1:]:\n",
    "            if end_six_idx - start_six_idx < 4:\n",
    "                continue\n",
    "            subseries = dice_series[start_six_idx:end_six_idx+1]\n",
    "            if np.mean(subseries == 6) > min_mean_to_fake:\n",
    "                labels[start_six_idx:end_six_idx+1] = False\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3214/3214 [02:08<00:00, 25.00it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "found_labels = find_labels(dice_series)\n",
    "print(np.mean(found_labels==labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 10000 artists>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = np.where(labels == True, 'g', 'r')\n",
    "plt.bar(np.arange(length), dice_series, color=colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 10000 artists>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWsAAAD4CAYAAAAqw8chAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAO0ElEQVR4nO3dbYxcV33H8d+v3jxAiGKnGUVuHHUdCUWKkIrdVZooKGpNCU6K6Ju8cNRCoCBLbalCWwnF4tW+bFUhQK0AK4SiNgRoCC2yBGkKQRVSMV2TEBw/NE5IG0dJPWkFAV40BP59MWfs2fE8nNmdu7P/8fcjjfY+nHvmf+6Z/WX2zh3HESEAwOb2S7MuAAAwHmENAAkQ1gCQAGENAAkQ1gCQwEITnV511VWxuLjYRNcAMJeOHDnyckS0hu1vJKwXFxe1srLSRNcAMJds/+eo/VwGAYAECGsASICwBoAECGsASICwBoAECGsASKAqrG1vtf2Q7RO2j9u+uenCAADn1N5n/TFJX4uIO21fLOn1DdYEAOgzNqxtXyHpVknvkaSIeFXSq82WBQDoVXMZZKektqTP2H7c9n22L+tvZHu/7RXbK+12e+qFetndJ6po7MHLo7b17+tv07d+tp5Bx4w5trqeceOo6bvbbLmiJntk7ef1sR6jxtZ7HvvarXod1MztqDHV1DBo36jtw2of1c+o47rrFcdWzfGgY2vHV1N/7fP2tfOyz18fV8+4OiZtV3vsep53HWrCekHSbkmfiIhdkn4q6d7+RhFxMCKWImKp1Rr69XYAwBrUhPVpSacj4nBZf0id8AYAbJCxYR0RL0l63vb1ZdNbJR1rtCoAwCq1d4P8iaQHyp0gz0p6b3MlAQD6VYV1RDwhaanZUgAAw/ANRgBIgLAGgAQIawBIgLAGgAQIawBIgLAGgAQIawBIgLAGgAQIawBIgLAGgAQIawBIgLAGgAQIawBIgLAGgAQIawBIgLAGgAQIawBIgLAGgAQIawBIgLAGgAQIawBIgLAGgAQIawBIgLAGgAQIawBIYKGmke3nJP1Y0s8lvRYRS00WBQBYrSqsi9+KiJcbqwQAMBSXQQAggdqwDkn/bPuI7f2DGtjeb3vF9kq73V5XUV52ZcPKdpO2HddVbX1r7au21kHt+rfVtFnrc9UcVsbXO85VY57ivNTUUbt9LX2NPqjvPKx13Bt0vqZtmud/3ab1O6GNrb82rN8SEbsl3S7pj23f2t8gIg5GxFJELLVarakWCQAXuqqwjogXys8zkr4s6cYmiwIArDY2rG1fZvvy7rKk2yQdbbowAMA5NXeDXC3py+5c01mQ9LmI+FqjVQEAVhkb1hHxrKRf24BaAABDcOseACRAWANAAoQ1ACRAWANAAoQ1ACRAWANAAoQ1ACRAWANAAoQ1ACRAWANAAoQ1ACRAWANAAoQ1ACRAWANAAoQ1ACRAWANAAoQ1ACRAWANAAoQ1ACRAWANAAoQ1ACRAWANAAoQ1ACRAWANAAoQ1ACRAWANAAtVhbXuL7cdtH2qyIADA+SZ5Z32PpONNFQIAGK4qrG3vkPQ7ku5rthwAwCC176w/KulDkn4xrIHt/bZXbK+02+1p1CYve9XPIU98Xvu6zidoO4kh/U5UW83TTLm/6ucaND6702a957SpOZmlUWNa63i7x1X07WWffUyFx8xzX22Nv04HPU/Tv9v9/W/Q63ZsWNt+h6QzEXFkVLuIOBgRSxGx1Gq1plYgAKDunfUtkt5p+zlJn5e0x/bfN1oVAGCVsWEdEQciYkdELEraJ+kbEfH7jVcGADiL+6wBIIGFSRpHxDclfbORSgAAQ/HOGgASIKwBIAHCGgASIKwBIAHCGgASIKwBIAHCGgASIKwBIAHCGgASIKwBIAHCGgASIKwBIAHCGgASIKwBIAHCGgASIKwBIAHCGgASIKwBIAHCGgASIKwBIAHCGgASIKwBIAHCGgASIKwBIAHCGgASGBvWti+1/R3b37P9lO3ljSgMAHDOQkWb/5O0JyJ+YvsiSd+y/dWI+HbDtQEAirFhHREh6Sdl9aLyiCaLAgCsVnXN2vYW209IOiPp0Yg4PKDNftsrtlfa7fbUCvSyBy5P1sng4ybtz8uevIa+5151/JC6auqY5DmH7hu2PFExQ45bY9/dsfWPcdzroGpe7MG1ePBzrto26jU0ao6nqeY8VrQZWV//8SP6O6+fynmuPs6j57xmX39/1b87lc+9karCOiJ+HhFvlrRD0o223zSgzcGIWIqIpVarNeUyAeDCNtHdIBHxQ0mPSdrbSDUAgIFq7gZp2d5all8n6W2STjRcFwCgR83dINslfdb2FnXC/YsRcajZsgAAvWruBnlS0q4NqAUAMATfYASABAhrAEiAsAaABAhrAEiAsAaABAhrAEiAsAaABAhrAEiAsAaABAhrAEiAsAaABAhrAEiAsAaABAhrAEiAsAaABAhrAEiAsAaABAhrAEiAsAaABAhrAEiAsAaABAhrAEiAsAaABAhrAEiAsAaABAhrAEhgbFjbvtb2Y7aP2X7K9j0bURgA4JyFijavSfrziPiu7cslHbH9aEQca7g2AEAx9p11RLwYEd8tyz+WdFzSNU0XBgA4Z6Jr1rYXJe2SdHjAvv22V2yvtNvttVdkT+cYu7ovL3t1P/0/11rDqDbj2q+hhrPjGHbckL5WHTfJc65lrqZ5fLebUv/Y8U/c8Yg+1tH/eed7yv3XF9LM+KZt0PmqOofS9MbhAa+xDVYd1rbfIOlLkj4YEa/074+IgxGxFBFLrVZrmjUCwAWvKqxtX6ROUD8QEQ83WxIAoF/N3SCW9GlJxyPiI82XBADoV/PO+hZJ75K0x/YT5XFHw3UBAHqMvXUvIr4lafN82gAAFyC+wQgACRDWAJAAYQ0ACRDWAJAAYQ0ACRDWAJAAYQ0ACRDWAJAAYQ0ACRDWAJAAYQ0ACRDWAJAAYQ0ACRDWAJAAYQ0ACRDWAJAAYQ0ACRDWAJAAYQ0ACRDWAJAAYQ0ACRDWAJAAYQ0ACRDWAJAAYQ0ACYwNa9v32z5j++hGFAQAOF/NO+u/lbS34ToAACOMDeuI+FdJ/7sBtQAAhpjaNWvb+22v2F5pt9vT6nb48y175PrwAz16fUa87OFj6KlxYJthY5jx2AbVWj1P63rizTGntbrnZE3nxms7dmT7mvM3wTleNb5xx7ni97pmzJ78uUY+Z42GX3dTC+uIOBgRSxGx1Gq1ptUtAEDcDQIAKRDWAJBAza17D0r6N0nX2z5t+33NlwUA6LUwrkFE3LURhQAAhuMyCAAkQFgDQAKENQAkQFgDQAKENQAkQFgDQAKENQAkQFgDQAKENQAkQFgDQAKENQAkQFgDQAKENQAkQFgDQAKENQAkQFgDQAKENQAkQFgDQAKENQAkQFgDQAKENQAkQFgDQAKENQAkQFgDQAKENQAkQFgDQAJVYW17r+2Ttk/ZvrfpogAAq40Na9tbJP2NpNsl3SDpLts3NF0YAOCcmnfWN0o6FRHPRsSrkj4v6XebLQsA0MsRMbqBfaekvRHx/rL+Lkm/EREf6Gu3X9L+snq9pJNrrOkqSS+v8disGPP8u9DGKzHmSf1qRLSG7VxYY6fniYiDkg6utx/bKxGxNIWS0mDM8+9CG6/EmKet5jLIC5Ku7VnfUbYBADZITVj/u6Q32t5p+2JJ+yR9pdmyAAC9xl4GiYjXbH9A0iOStki6PyKearCmdV9KSYgxz78LbbwSY56qsR8wAgBmj28wAkAChDUAJLBpwnqevtJu+1rbj9k+Zvsp2/eU7VfaftT20+XntrLdtj9exv6k7d09fd1d2j9t++5ZjamG7S22H7d9qKzvtH24jOsL5QNq2b6krJ8q+xd7+jhQtp+0/fYZDaWa7a22H7J9wvZx2zfP8zzb/tPymj5q+0Hbl87jPNu+3/YZ20d7tk1tXm3/uu3vl2M+bttji4qImT/U+eDyGUnXSbpY0vck3TDrutYxnu2SdpflyyX9hzpf1f9LSfeW7fdK+ouyfIekr0qypJskHS7br5T0bPm5rSxvm/X4Roz7zyR9TtKhsv5FSfvK8icl/WFZ/iNJnyzL+yR9oSzfUOb+Ekk7y2tiy6zHNWbMn5X0/rJ8saSt8zrPkq6R9ANJr+uZ3/fM4zxLulXSbklHe7ZNbV4lfae0dTn29rE1zfqklMJvlvRIz/oBSQdmXdcUx/dPkt6mzrc6t5dt2yWdLMufknRXT/uTZf9dkj7Vs31Vu830UOf++69L2iPpUHkRvixpoX+O1bmz6OayvFDauX/ee9ttxoekK0p4uW/7XM5zCevnS/gslHl++7zOs6TFvrCeyryWfSd6tq9qN+yxWS6DdF8EXafLtvTKn367JB2WdHVEvFh2vSTp6rI8bPyZzstHJX1I0i/K+i9L+mFEvFbWe2s/O66y/0elfabxSp13hW1JnymXf+6zfZnmdJ4j4gVJfyXpvyS9qM68HdH8z3PXtOb1mrLcv32kzRLWc8n2GyR9SdIHI+KV3n3R+U/qXNw3afsdks5ExJFZ17LBFtT5U/kTEbFL0k/V+fP4rDmb523q/CNuOyX9iqTLJO2daVEzMot53SxhPXdfabd9kTpB/UBEPFw2/7ft7WX/dklnyvZh489yXm6R9E7bz6nzrzLukfQxSVttd7941Vv72XGV/VdI+h/lGW/XaUmnI+JwWX9InfCe13n+bUk/iIh2RPxM0sPqzP28z3PXtOb1hbLcv32kzRLWc/WV9vLJ7qclHY+Ij/Ts+oqk7ifCd6tzLbu7/d3lU+WbJP2o/Ln1iKTbbG8r72puK9s2lYg4EBE7ImJRnbn7RkT8nqTHJN1ZmvWPt3se7izto2zfV+4i2Cnpjep8ELMpRcRLkp63fX3Z9FZJxzSn86zO5Y+bbL++vMa7453ree4xlXkt+16xfVM5j+/u6Wu4WV/E77nIfoc6d008I+nDs65nnWN5izp/Ij0p6YnyuEOd63Vfl/S0pH+RdGVpb3X+Bw/PSPq+pKWevv5A0qnyeO+sx1Yx9t/UubtBrlPnl/CUpH+QdEnZfmlZP1X2X9dz/IfLeTipik/IZ/2Q9GZJK2Wu/1GdT/3ndp4lLUs6IemopL9T546OuZtnSQ+qc13+Z+r8BfW+ac6rpKVyDp+R9Nfq+5B60IOvmwNAApvlMggAYATCGgASIKwBIAHCGgASIKwBIAHCGgASIKwBIIH/B6AhzKNf0ZijAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = np.where(found_labels == True, 'g', 'r')\n",
    "plt.bar(np.arange(length), dice_series, color=colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 4. (4p) \n",
    "W tym zadaniu powinieneś zrekonstruować „parametry” krupiera. Mamy dwie sześcienne kości o nieznanych rozkładach (każdy rozkład to 6 liczb dodatnich, sumujących się do jedynki), zaczynamy od losowo wybranej kości1. Podobnie jak w poprzednim zadaniu p1 i p2 to prawdopodobieństwa zmiany kości. Na SKOSIe znajdziesz zestaw 20000 obserwacji (wyników rzutów kością), poczynionych dla tego modelu (ale do testów możesz też używać danych wygenerowanych w poprzednim zadaniu). Masz zrekonstruować model, uruchom Twój program dla kilku prefiksów dostępnych danych i porównaj wyniki.\n",
    "\n",
    "Zastanów się, jak zainicjować model. Czy rozpoczynanie od równych prawdopodobieństw to dobry pomysł?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
