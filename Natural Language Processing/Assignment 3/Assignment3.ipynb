{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import re\n",
    "from typing import Tuple, DefaultDict, Dict, List, Optional\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 1. (5p) \n",
    "W zadaniu tym masz napisać system, który bierze na wejściu (ztokenizowany) tekst w języku polskim, pozbawiony wielkich liter oraz polskich znaków diakrytycznych i wypisuje na wyjściu poprawny tekst w języku polskim. Zakładamy, że literka „ź” na wejściu jest reprezentowana przez „z” (a nie „x”). Liczymy dwie miary dokładności:\n",
    "\n",
    "a) Dokładność polskawa, czyli liczba słów poprawnie zrekonstruowanych (modulo wielkość liter, której nie uwzględniamy w tej mierze) podzielona przez liczbę słów w ogóle\n",
    "\n",
    "b) Dokładność pełna, czyli liczba słów poprawnie zrekonstruowanych podzielona przez liczbę słów (tu uwzględniamy zarówno ogonki jak i wielkość liter).\n",
    "\n",
    "Ostatecznym wynikiem będzie średnia geometryczna tych liczb. W tym zadaniu sprawdzany jest poziom basic, to znaczy że prezentowane rozwiązanie powinno:\n",
    "- rekonstruować stokenizowany tekst,\n",
    "- wykorzystywać dane dotyczące unigramów z części uczącej korpusu,\n",
    "- w jakiś sposób (dowolny sensowny) uwzględniać informacje o dłuższych ciągach słów.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000000/1000000 [00:21<00:00, 47372.26it/s]\n"
     ]
    }
   ],
   "source": [
    "corpus_count = defaultdict(int)\n",
    "with open('data.nogit/polish_corpora.txt', 'r') as f:\n",
    "    for _ in trange(1000000):\n",
    "        row = f.readline()\n",
    "        text = preprocess(row)\n",
    "        for w in text.split():\n",
    "            corpus_count[w] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text: str) -> str:\n",
    "    text = re.sub('[^a-zA-ZęóąśłżźńĘÓĄŚŁŻŹŃ ]', '', text)\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text: str) -> str:\n",
    "    polish_chars_replacements = {'ę': 'e', 'ó': 'o', 'ą': 'a', 'ś': 's', 'ł': 'l', 'ż': 'z', 'ź': 'z', 'ń': 'n'}\n",
    "    text = text.lower()\n",
    "    for polish, replacement in polish_chars_replacements.items():\n",
    "        text = text.replace(polish, replacement)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_norm_bigrams = np.min(list(bigrams_count.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_text(\n",
    "    original: str, \n",
    "    corpora_counts: DefaultDict[str, int], \n",
    "    bigrams: DefaultDict[str, List[str]],\n",
    "    bigram_count: DefaultDict[Tuple[str, str], float],\n",
    "    tokenized_to_word_mapping: Dict[str, str],\n",
    ") -> str:\n",
    "    assert len(original) > 0\n",
    "    reconstructed_words = []\n",
    "    tokenized = tokenize(original)\n",
    "    prev_word = None\n",
    "    for tokenized_word in tokenized.split():\n",
    "        word = reconstruct_word(prev_word, tokenized_word, corpora_counts, bigrams, bigram_count, tokenized_to_word_mapping)\n",
    "        reconstructed_words.append(word)\n",
    "        prev_word = tokenized_word\n",
    "        \n",
    "    # Start with a big letter\n",
    "    first_word_list = list(reconstructed_words[0])\n",
    "    first_word_list[0] = first_word_list[0].upper()\n",
    "    reconstructed_words[0] = ''.join(first_word_list)\n",
    "    return ' '.join(reconstructed_words)\n",
    "\n",
    "alpha = 0.5\n",
    "def reconstruct_word(\n",
    "    prev_word: Optional[str],\n",
    "    tokenized_word: str, \n",
    "    corpora_counts: DefaultDict[str, int], \n",
    "    bigrams: DefaultDict[str, List[str]],\n",
    "    bigram_count: DefaultDict[Tuple[str, str], float],\n",
    "    tokenized_to_word_mapping: DefaultDict[str, List[str]],\n",
    ") -> str:\n",
    "    if tokenized_word not in tokenized_to_word_mapping:\n",
    "        return tokenized_word\n",
    "    possible_words = tokenized_to_word_mapping[tokenized_word]\n",
    "    \n",
    "    if prev_word is not None and prev_word in bigrams:\n",
    "        next_words = list(bigrams[prev_word].intersection(set(possible_words)))\n",
    "        if len(next_words) > 0:\n",
    "            probs = [(alpha * bigram_count[prev_word, w] * to_norm_bigrams) **0.75 + \n",
    "                     ((1-alpha) * corpora_counts[w]) ** 0.75 \n",
    "                     for w in next_words]\n",
    "            best_word = next_words[np.argmax(probs)]\n",
    "            return best_word\n",
    "    \n",
    "    probs = [corpora_counts[w] for w in possible_words]\n",
    "    best_word = possible_words[np.argmax(probs)]\n",
    "    return best_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity(original: str, reconstucted: str) -> Tuple[float, float]:\n",
    "    similarities = [0, 0]\n",
    "    for original_word, recontructed_word in zip(original.split(), reconstucted.split()):\n",
    "        if original_word.lower() == recontructed_word.lower():\n",
    "            similarities[0] += 1\n",
    "            \n",
    "            if original_word == recontructed_word:\n",
    "                similarities[1] += 1\n",
    "    \n",
    "    number_of_words = original.count(' ') + 1\n",
    "    return np.sqrt(np.prod(similarities)) / number_of_words\n",
    "#     return similarities[0] / number_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora_counts = pickle.load(open('data.nogit/corpora_counts.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved = pickle.load(open('bigrams_saved.nogit/saved.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = saved['from_words']['bigrams']\n",
    "bigrams_count = saved['from_words']['bigrams_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2980295/2980295 [01:06<00:00, 45063.15it/s] \n"
     ]
    }
   ],
   "source": [
    "tokenized_to_word_mapping = defaultdict(list)\n",
    "for word in tqdm(corpora_counts.keys()):\n",
    "    tokenized_word = tokenize(word)\n",
    "    tokenized_to_word_mapping[tokenized_word].append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for corpus in ['prusa', 'orzeszkowej', 'sienkiewicza']:\n",
    "    sentences.extend(open(f'data.nogit/korpus_{corpus}.txt', 'r').read().split('\\n'))\n",
    "preprocessed_sentences = list(filter(lambda sent: len(sent) > 0, [preprocess(sent) for sent in sentences]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Antek',\n",
       " 'Antek urodził się we wsi nad Wisłą',\n",
       " 'Wieś leżała w niewielkiej dolinie Od północy otaczały ją wzgórza spadziste porosłe sosnowym lasem a od południa wzgórza garbate zasypane leszczyną tarniną i głogiem Tam najgłośniej śpiewały ptaki i najczęściej chodziły wiejskie dzieci rwa orzechy albo wybiera gniazda',\n",
       " 'Kiedyś stanął na środku wsi zdawało ci się że oba pasma gór biegną ku sobie ażeby zetkną się tam gdzie z rana wstaje czerwone słońce Ale było to złudzenie',\n",
       " 'Za wsią bowiem ciągnęła się między wzgórzami dolina przecięta rzeczułką i przykryta zieloną łąką',\n",
       " 'Tam pasano bydlątka i tam cienkonogie bociany chodziły polowa na żaby kukające wieczorami',\n",
       " 'Od zachodu wieś miała tamę za tamą Wisłę a za Wisłą znowu wzgórza wapienne nagie',\n",
       " 'Każdy chłopski dom szarą słomą pokryty miał ogródek a w ogródku śliwki węgierki spomiędzy których wida było komin sadzą uczerniony i pożarną drabinkę Drabiny te zaprowadzono nie od dawna a ludzie myśleli że one lepiej chroni będą chaty od ognia niż dawniej bocianie gniazda Toteż gdy płonął jaki budynek dziwili się bardzo ale go nie ratowali',\n",
       " 'Wida że na tego gospodarza był dopust boski mówili między sobą Spalił się cho miał przecie nową drabinę i cho zapłacił śtraf za starą co to były u niej połamane szczeble',\n",
       " 'W takiej wsi urodził się Antek Położyli go w niemalowanej kołysce co została po zmarłym bracie i sypiał w niej przez dwa lata Potem przyszła mu na świat siostra Rozalia więc musiał jej miejsca ustąpi a sam jako osoba dorosła przenieś się na ławę']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/17180 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t0.9206766149755737\n",
      "Wieś leżała w niewielkiej dolinie Od północy otaczały ją wzgórza spadziste porosłe sosnowym lasem a od południa wzgórza garbate zasypane leszczyną tarniną i głogiem Tam najgłośniej śpiewały ptaki i najczęściej chodziły wiejskie dzieci rwa orzechy albo wybiera gniazda\n",
      "Wieś leżała w niewielkiej dolinie od północy otaczały ją wzgórza spadziste porosłe sosnowym lasem a od południa wzgórza garbate zasypane leszczyna tarnina i głogiem tam najgłośniej śpiewały ptaki i najczęściej chodziły wiejskie dzieci rwa orzechy albo wybiera gniazda\n",
      "\n",
      "0.9206766149755737 0.9206766149755737 0.9206766149755737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "similarities = []\n",
    "for sentence in tqdm(preprocessed_sentences[2:], position=0, leave=True):\n",
    "    reconstructed_sentence = reconstruct_text(sentence, corpus_count, bigrams, bigrams_count, tokenized_to_word_mapping)\n",
    "    similarity = compute_similarity(original=sentence, reconstucted=reconstructed_sentence)\n",
    "    similarities.append(similarity)\n",
    "    print(f'\\t\\t{similarity}\\n{sentence}\\n{reconstructed_sentence}\\n')\n",
    "    break\n",
    "\n",
    "print(np.min(similarities), np.mean(similarities), np.max(similarities))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 2. (3 + Xp) \n",
    "W tym zadaniu rozwiązać należy dokładnie ten sam problem, co w poprzednim zadaniu. Żeby zadanie było uznane za zrobione poprawnie, wynik Twojego programu (na zbiorze ewaluacyjnym), musi być wyższy niż K = 0.955. Dodatkowo, jeżeli wynik R Twojego programu będzie większy niż Y = 0.96, to za zadanie dostaniesz 4 × $\\frac{R−Y}{1-Y}$ . Dodatkowa premia to 4 punkty za najlepszy program, 3 punkty za drugie miejsce, 2 punkty za trzecie i 1 punkt za czwarte (liczone we wszystkich grupach). Dozwolone jest korzystanie z korpusu PolEval (pierwszy milion wierszy), N-gramów NKJP oraz Morfologika. Zbiór testowy to kolejne 200 tysięcy wierszy korpusu PolEvala."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_validation_set():\n",
    "    i = 0\n",
    "    validation_set = []\n",
    "    with open('data.nogit/polish_corpora.txt', 'r') as f:\n",
    "        while i < 1e6+200000:\n",
    "            row = f.readline()\n",
    "            i += 1\n",
    "            if i < 1e6:\n",
    "                continue\n",
    "            validation_set.append(preprocess(row))\n",
    "    return validation_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set = create_validation_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200001/200001 [01:16<00:00, 2623.40it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9106598472302138"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = 0\n",
    "similarities = []\n",
    "for sentence in tqdm(validation_set, position=0, leave=True):\n",
    "    reconstructed_sentence = reconstruct_text(sentence, corpora_counts, bigrams, bigrams_count, tokenized_to_word_mapping)\n",
    "    similarity = compute_similarity(original=sentence, reconstucted=reconstructed_sentence)\n",
    "    similarities.append(similarity)\n",
    "#     print(f'\\t\\t{similarity}\\n{sentence}\\n{reconstructed_sentence}\\n')\n",
    "#     break\n",
    "np.mean(similarities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 3. (4p) \n",
    "W zadaniu tym zajmiemy się omawianym na wykładzie ukrytym łańcuchem Markowa, na przykładzie nieuczciwego krupiera rzucającego kością. Przypominam zasady:\n",
    "1. Krupier ma dwie kości, uczciwą i oszukaną.\n",
    "2. Kość oszukana daje 6 oczek z p = 1/2, a pozostałe wyniki z p = 1/10\n",
    "3. Krupier zmienia kość uczciwą na nieuczciwą z p1 = 0.04, a nieuczciwą na uczciwą z p2 = 0.05\n",
    "4. Zaczynamy od uczciwej kości.\n",
    "\n",
    "Napisz program, który dla danego ciągu rzutów (który musisz sam wygenerować) wypisuje ciąg stanów (u – kość uczciwa, n – kość nieuczciwa, długość rzędu 10000), w sposób maksymalizujący liczbę prawidłowo zgadniętych stanów. Rozwiąż to zadanie na dwa sposoby:\n",
    "- Proponując heurystyczny algorytm decydujący na podstawie badania skupisk szóstek\n",
    "- Implementując poprawny algorytm, bazujący na zmiennych α oraz β (zobacz wykład o HMM).\n",
    "\n",
    "Wykonując eksperymenty, oszacuj poprawność działania obu algorytmów, mierzoną liczbą poprawnie zgadniętych stanów (podzieloną przez długość ciągu)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_probs = np.full(6, 1/6)\n",
    "trick_probs = np.append(np.full(5, 1/10), 1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_to_trick_change_prob = 0.04\n",
    "trick_to_valid_change_prob = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_probs = np.array([[0.96, 0.04],\n",
    "                         [0.05, 0.95]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_series(length: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    uses_valid = True\n",
    "    dice_series, labels = [], []\n",
    "    for _ in range(length):\n",
    "        labels.append(uses_valid)\n",
    "        if uses_valid:\n",
    "            dice = np.random.choice(6, p=valid_probs) + 1\n",
    "            if np.random.random() < valid_to_trick_change_prob:\n",
    "                uses_valid = False\n",
    "        else:\n",
    "            dice = np.random.choice(6, p=trick_probs) + 1\n",
    "            if np.random.random() < trick_to_valid_change_prob:\n",
    "                uses_valid = True\n",
    "        dice_series.append(dice)\n",
    "    return np.array(dice_series), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 10000\n",
    "dice_series, labels = generate_series(length=length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_heuristic_labels(dice_series: np.ndarray, min_mean_to_fake: int=0.54) -> np.ndarray:\n",
    "    labels = np.ones_like(dice_series, dtype=bool)\n",
    "    \n",
    "    six_idxs = np.flatnonzero(dice_series == 6)\n",
    "    for i, start_six_idx in tqdm(enumerate(six_idxs), total=len(six_idxs)):\n",
    "        if start_six_idx == 0:\n",
    "            continue\n",
    "        for end_six_idx in six_idxs[i+1:]:\n",
    "            if end_six_idx - start_six_idx < 4:\n",
    "                continue\n",
    "            subseries = dice_series[start_six_idx:end_six_idx+1]\n",
    "            if np.mean(subseries == 6) > min_mean_to_fake:\n",
    "                labels[start_six_idx:end_six_idx+1] = False\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trick_probs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4, 6, 6, 1, 4, 6, 1, 3, 6, 1]),\n",
       " array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True]))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds,_ = generate_series(10)\n",
    "b = np.zeros((len(ds), 2, 2))\n",
    "for i, result in enumerate(ds):\n",
    "    for dice_type in range(2):\n",
    "        is_valid_dice = dice_type == 0\n",
    "        for next_dice_type in range(2):\n",
    "            is_next_dice_valid = next_dice_type == 0\n",
    "            if is_valid_dice:\n",
    "                b[i, is_valid_dice, is_next_dice_valid] = valid_probs[result-1] * change_probs[dice_type, next_dice_type]\n",
    "            else:\n",
    "                b[i, is_valid_dice, is_next_dice_valid] = trick_probs[result-1] * change_probs[dice_type, next_dice_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_hmm_labels(\n",
    "    dice_series: np.ndarray, \n",
    "    valid_probs: np.ndarray, \n",
    "    trick_probs: np.ndarray, \n",
    "    change_probs: np.ndarray,\n",
    ") -> np.ndarray:\n",
    "    b = np.zeros((len(dice_series), 2, 2))\n",
    "    for i, result in enumerate(dice_series):\n",
    "        for dice_type in range(2):\n",
    "            for next_dice_type in range(2):\n",
    "                if dice_type == 0:\n",
    "                    b[i, dice_type, next_dice_type] = valid_probs[result-1] * change_probs[dice_type, next_dice_type]\n",
    "                else:\n",
    "                    b[i, dice_type, next_dice_type] = trick_probs[result-1] * change_probs[dice_type, next_dice_type]\n",
    "    \n",
    "    reconstruct_list = [[0, 0] for _ in range(len(dice_series))]\n",
    "    \n",
    "    reconstruct_list[-1] = np.sum(b[-1][0]), np.sum(b[-1][1])\n",
    "    print(reconstruct_list[-1])\n",
    "    for i in reversed(range(len(dice_series)-1)):\n",
    "        for is_valid_dice in range(2):\n",
    "            reconstruct_list[i][is_valid_dice] = \\\n",
    "                reconstruct_list[i+1][is_valid_dice] * b[i, is_valid_dice, is_valid_dice] + \\\n",
    "                reconstruct_list[i+1][1-is_valid_dice] * b[i, is_valid_dice, 1-is_valid_dice]\n",
    "        \n",
    "#         min_val = np.min(reconstruct_list[i+1])\n",
    "        x = 5.4\n",
    "        reconstruct_list[i] = reconstruct_list[i][0] * x, reconstruct_list[i][1] * x\n",
    "        \n",
    "    \n",
    "    results = []\n",
    "    print(reconstruct_list[:10])\n",
    "    for i in range(len(dice_series)):\n",
    "        if reconstruct_list[i][0] > reconstruct_list[i][1]:\n",
    "            results.append(True)\n",
    "        else:\n",
    "            results.append(False)\n",
    "    \n",
    "    return np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 6, 5, ..., 3, 1, 5])"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dice_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.16666666666666663, 0.1)\n",
      "[(1.737651470906535e-30, 3.409207780510705e-30), (1.7380810484255125e-30, 6.554151251858121e-30), (1.9093874391283623e-30, 2.4547305838502114e-30), (2.0149809054724426e-30, 4.6789982444492304e-30), (2.2611052709883975e-30, 1.705165314957426e-30), (2.4839710864165437e-30, 3.1931736756806614e-30), (2.8293002235490128e-30, 1.0959914797276978e-30), (3.1926362804921235e-30, 1.9684021445505074e-30), (3.54307406206449e-30, 3.650563635233462e-30), (3.8126366910203926e-30, 6.915443361746415e-30)]\n"
     ]
    }
   ],
   "source": [
    "hmm_labels = find_hmm_labels(dice_series, valid_probs, trick_probs, change_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4999"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(hmm_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7596"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(hmm_labels==labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3329/3329 [02:31<00:00, 21.96it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "heuristic_labels = find_heuristic_labels(dice_series)\n",
    "print(np.mean(heuristic_labels==labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 10000 artists>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = np.where(labels == True, 'g', 'r')\n",
    "plt.bar(np.arange(length), dice_series, color=colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 10000 artists>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = np.where(heuristic_labels == True, 'g', 'r')\n",
    "plt.bar(np.arange(length), dice_series, color=colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 4. (4p) \n",
    "W tym zadaniu powinieneś zrekonstruować „parametry” krupiera. Mamy dwie sześcienne kości o nieznanych rozkładach (każdy rozkład to 6 liczb dodatnich, sumujących się do jedynki), zaczynamy od losowo wybranej kości1. Podobnie jak w poprzednim zadaniu p1 i p2 to prawdopodobieństwa zmiany kości. Na SKOSIe znajdziesz zestaw 20000 obserwacji (wyników rzutów kością), poczynionych dla tego modelu (ale do testów możesz też używać danych wygenerowanych w poprzednim zadaniu). Masz zrekonstruować model, uruchom Twój program dla kilku prefiksów dostępnych danych i porównaj wyniki.\n",
    "\n",
    "Zastanów się, jak zainicjować model. Czy rozpoczynanie od równych prawdopodobieństw to dobry pomysł?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
