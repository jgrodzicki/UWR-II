{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pickle\n",
    "import re\n",
    "from typing import Tuple, DefaultDict, Dict, List, Optional\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 1. (5p) \n",
    "W zadaniu tym masz napisać system, który bierze na wejściu (ztokenizowany) tekst w języku polskim, pozbawiony wielkich liter oraz polskich znaków diakrytycznych i wypisuje na wyjściu poprawny tekst w języku polskim. Zakładamy, że literka „ź” na wejściu jest reprezentowana przez „z” (a nie „x”). Liczymy dwie miary dokładności:\n",
    "\n",
    "a) Dokładność polskawa, czyli liczba słów poprawnie zrekonstruowanych (modulo wielkość liter, której nie uwzględniamy w tej mierze) podzielona przez liczbę słów w ogóle\n",
    "\n",
    "b) Dokładność pełna, czyli liczba słów poprawnie zrekonstruowanych podzielona przez liczbę słów (tu uwzględniamy zarówno ogonki jak i wielkość liter).\n",
    "\n",
    "Ostatecznym wynikiem będzie średnia geometryczna tych liczb. W tym zadaniu sprawdzany jest poziom basic, to znaczy że prezentowane rozwiązanie powinno:\n",
    "- rekonstruować stokenizowany tekst,\n",
    "- wykorzystywać dane dotyczące unigramów z części uczącej korpusu,\n",
    "- w jakiś sposób (dowolny sensowny) uwzględniać informacje o dłuższych ciągach słów.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text: str) -> str:\n",
    "    text = re.sub('[^a-zA-ZęóąśłżźńĘÓĄŚŁŻŹŃ ]', '', text)\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text: str) -> str:\n",
    "    polish_chars_replacements = {'ę': 'e', 'ó': 'o', 'ą': 'a', 'ś': 's', 'ł': 'l', 'ż': 'z', 'ź': 'z', 'ń': 'n'}\n",
    "    text = text.lower()\n",
    "    for polish, replacement in polish_chars_replacements.items():\n",
    "        text = text.replace(polish, replacement)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_text(\n",
    "    original: str, \n",
    "    corpora_counts: DefaultDict[str, int], \n",
    "    bigrams: DefaultDict[str, List[str]],\n",
    "    bigram_count: DefaultDict[Tuple[str, str], float],\n",
    "    tokenized_to_word_mapping: Dict[str, str],\n",
    ") -> str:\n",
    "    assert len(original) > 0\n",
    "    reconstructed_words = []\n",
    "    tokenized = tokenize(original)\n",
    "    prev_word = None\n",
    "    for tokenized_word in tokenized.split():\n",
    "        word = reconstruct_word(prev_word, tokenized_word, corpora_counts, bigrams, bigram_count, tokenized_to_word_mapping)\n",
    "        reconstructed_words.append(word)\n",
    "        prev_word = tokenized_word\n",
    "        \n",
    "    # Start with a big letter\n",
    "    first_word_list = list(reconstructed_words[0])\n",
    "    first_word_list[0] = first_word_list[0].upper()\n",
    "    reconstructed_words[0] = ''.join(first_word_list)\n",
    "    return ' '.join(reconstructed_words)\n",
    "\n",
    "def reconstruct_word(\n",
    "    prev_word: Optional[str],\n",
    "    tokenized_word: str, \n",
    "    corpora_counts: DefaultDict[str, int], \n",
    "    bigrams: DefaultDict[str, List[str]],\n",
    "    bigram_count: DefaultDict[Tuple[str, str], float],\n",
    "    tokenized_to_word_mapping: DefaultDict[str, List[str]],\n",
    ") -> str:\n",
    "    if tokenized_word not in tokenized_to_word_mapping:\n",
    "        return tokenized_word\n",
    "    possible_words = tokenized_to_word_mapping[tokenized_word]\n",
    "    \n",
    "    if prev_word is not None and prev_word in bigrams:\n",
    "        next_words = list(bigrams[prev_word].intersection(set(possible_words)))\n",
    "        if len(next_words) > 0:\n",
    "            probs = [bigram_count[prev_word, w] for w in next_words]\n",
    "            best_word = next_words[np.argmax(probs)]\n",
    "            return best_word\n",
    "    \n",
    "    probs = [corpora_counts[w] for w in possible_words]\n",
    "    best_word = possible_words[np.argmax(probs)]\n",
    "    return best_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity(original: str, reconstucted: str) -> float:\n",
    "    similarities = [0, 0]\n",
    "    for original_word, recontructed_word in zip(original.split(), reconstucted.split()):\n",
    "        if original_word.lower() == recontructed_word.lower():\n",
    "            similarities[0] += 1\n",
    "            \n",
    "            if original_word == recontructed_word:\n",
    "                similarities[1] += 1\n",
    "    \n",
    "    number_of_words = original.count(' ') + 1\n",
    "    return np.sqrt(similarities[0] * similarities[1]) / number_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora_counts = pickle.load(open('data.nogit/corpora_counts.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved = pickle.load(open('bigrams_saved.nogit/saved.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = saved['from_words']['bigrams']\n",
    "bigrams_count = saved['from_words']['bigrams_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2980295/2980295 [00:18<00:00, 160977.29it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_to_word_mapping = defaultdict(list)\n",
    "for word in tqdm(corpora_counts.keys()):\n",
    "    tokenized_word = tokenize(word)\n",
    "    tokenized_to_word_mapping[tokenized_word].append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences = [\n",
    "#     'No i to był bardzo ciekawy wyjazd',\n",
    "#     'Święcie wierzyłem w niezawisłość polskich sądów'\n",
    "# ]\n",
    "\n",
    "sentences = open('data.nogit/korpus_prusa.txt', 'r').read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16760/16760 [00:14<00:00, 1195.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.8938724110278521 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "similarities = []\n",
    "for sentence in tqdm(sentences, position=0, leave=True):\n",
    "    sentence = preprocess(sentence)\n",
    "    if len(sentence) == 0:\n",
    "        continue\n",
    "    reconstructed_sentence = reconstruct_text(sentence, corpora_counts, bigrams, bigrams_count, tokenized_to_word_mapping)\n",
    "    similarity = compute_similarity(original=sentence, reconstucted=reconstructed_sentence)\n",
    "    similarities.append(similarity)\n",
    "#     print(f'\\t\\t{similarity}\\n{sentence}\\n{reconstructed_sentence}\\n')\n",
    "    \n",
    "print(np.min(similarities), np.mean(similarities), np.max(similarities))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 2. (3 + Xp) \n",
    "W tym zadaniu rozwiązać należy dokładnie ten sam problem, co w poprzednim zadaniu. Żeby zadanie było uznane za zrobione poprawnie, wynik Twojego programu (na zbiorze ewaluacyjnym), musi być wyższy niż K = 0.955. Dodatkowo, jeżeli wynik R Twojego programu będzie większy niż Y = 0.96, to za zadanie dostaniesz 4 × $\\frac{R−Y}{1-Y}$ . Dodatkowa premia to 4 punkty za najlepszy program, 3 punkty za drugie miejsce, 2 punkty za trzecie i 1 punkt za czwarte (liczone we wszystkich grupach). Dozwolone jest korzystanie z korpusu PolEval (pierwszy milion wierszy), N-gramów NKJP oraz Morfologika. Zbiór testowy to kolejne 200 tysięcy wierszy korpusu PolEvala."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_validation_set():\n",
    "    i = 0\n",
    "    validation_set = []\n",
    "    with open('data.nogit/polish_corpora.txt', 'r') as f:\n",
    "        while i < 1e6+200000:\n",
    "            row = f.readline()\n",
    "            i += 1\n",
    "            if i < 1e6:\n",
    "                continue\n",
    "            validation_set.append(preprocess(row))\n",
    "    return validation_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set = create_validation_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200001/200001 [06:41<00:00, 497.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.8842884585361235 1.0\n"
     ]
    }
   ],
   "source": [
    "similarities = []\n",
    "for sentence in tqdm(validation_set, position=0, leave=True):\n",
    "    sentence = preprocess(sentence)\n",
    "    if len(sentence) == 0:\n",
    "        continue\n",
    "    reconstructed_sentence = reconstruct_text(sentence, corpora_counts, bigrams, bigrams_count, tokenized_to_word_mapping)\n",
    "    similarity = compute_similarity(original=sentence, reconstucted=reconstructed_sentence)\n",
    "    similarities.append(similarity)\n",
    "#     print(f'\\t\\t{similarity}\\n{sentence}\\n{reconstructed_sentence}\\n')\n",
    "    \n",
    "print(np.min(similarities), np.mean(similarities), np.max(similarities))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 3. (4p) \n",
    "W zadaniu tym zajmiemy się omawianym na wykładzie ukrytym łańcuchem Markowa, na przykładzie nieuczciwego krupiera rzucającego kością. Przypominam zasady:\n",
    "1. Krupier ma dwie kości, uczciwą i oszukaną.\n",
    "2. Kość oszukana daje 6 oczek z p = 1/2, a pozostałe wyniki z p = 1/10\n",
    "3. Krupier zmienia kość uczciwą na nieuczciwą z p1 = 0.04, a nieuczciwą na uczciwą z p2 = 0.05\n",
    "4. Zaczynamy od uczciwej kości.\n",
    "\n",
    "Napisz program, który dla danego ciągu rzutów (który musisz sam wygenerować) wypisuje ciąg stanów (u – kość uczciwa, n – kość nieuczciwa, długość rzędu 10000), w sposób maksymalizujący liczbę prawidłowo zgadniętych stanów. Rozwiąż to zadanie na dwa sposoby:\n",
    "- Proponując heurystyczny algorytm decydujący na podstawie badania skupisk szóstek\n",
    "- Implementując poprawny algorytm, bazujący na zmiennych α oraz β (zobacz wykład o HMM).\n",
    "\n",
    "Wykonując eksperymenty, oszacuj poprawność działania obu algorytmów, mierzoną liczbą poprawnie zgadniętych stanów (podzieloną przez długość ciągu)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 4. (4p) \n",
    "W tym zadaniu powinieneś zrekonstruować „parametry” krupiera. Mamy dwie sześcienne kości o nieznanych rozkładach (każdy rozkład to 6 liczb dodatnich, sumujących się do jedynki), zaczynamy od losowo wybranej kości1. Podobnie jak w poprzednim zadaniu p1 i p2 to prawdopodobieństwa zmiany kości. Na SKOSIe znajdziesz zestaw 20000 obserwacji (wyników rzutów kością), poczynionych dla tego modelu (ale do testów możesz też używać danych wygene- rowanych w poprzednim zadaniu). Masz zrekonstruować model, uruchom Twój program dla kilku prefiksów dostępnych danych i porównaj wyniki.\n",
    "\n",
    "Zastanów się, jak zainicjować model. Czy rozpoczynanie od równych prawdopodobieństw to dobry pomysł?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
