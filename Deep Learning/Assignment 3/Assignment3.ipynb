{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment3_Grodzicki_Jakub.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0587df20b83a4303a0b2c427d2221889": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d4d7733316b346e18b6568b8291c02d0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c3f494e962c34eba86377798bf21b0eb",
              "IPY_MODEL_4a153190700f49bdb2bd96d0fbfca8f1"
            ]
          }
        },
        "d4d7733316b346e18b6568b8291c02d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c3f494e962c34eba86377798bf21b0eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_616607599e12427faf70f8f824ab0257",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 50000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 50000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2c5c8ceaa6024424babbbc5671eaf35a"
          }
        },
        "4a153190700f49bdb2bd96d0fbfca8f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b12423ee45784081b87faf702761d9f6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 50000/50000 [00:06&lt;00:00, 7196.98it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0444d22486c54fcb96a42562c916d2a0"
          }
        },
        "616607599e12427faf70f8f824ab0257": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2c5c8ceaa6024424babbbc5671eaf35a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b12423ee45784081b87faf702761d9f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0444d22486c54fcb96a42562c916d2a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "573f5aa4ab43432abbde5b60b6332d2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_df2797dde693461a90c47657f9b4c2d1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c67a0e3b38c643648a2b6d6f88858d94",
              "IPY_MODEL_2d38b1f1ca534b238ecdbef83bd16cb1"
            ]
          }
        },
        "df2797dde693461a90c47657f9b4c2d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c67a0e3b38c643648a2b6d6f88858d94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_04404a275afe45d9afab96dd7f9363e8",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 10000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 10000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a1feea427fe4450da5014fff389b689e"
          }
        },
        "2d38b1f1ca534b238ecdbef83bd16cb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8fbb872595c5430295006133742d40f0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 10000/10000 [00:12&lt;00:00, 797.31it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_82e747ff73bc4e1ea5b1213f6c9e53fc"
          }
        },
        "04404a275afe45d9afab96dd7f9363e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a1feea427fe4450da5014fff389b689e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8fbb872595c5430295006133742d40f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "82e747ff73bc4e1ea5b1213f6c9e53fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dfa4db0de0f64d61ba19ef55d2d18907": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e0f78ce31cd846fdb5f0d447de4e8381",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a482d16528e3491ea30f43a2e2304005",
              "IPY_MODEL_6d9cde79a0c64874a77691743bca10be"
            ]
          }
        },
        "e0f78ce31cd846fdb5f0d447de4e8381": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a482d16528e3491ea30f43a2e2304005": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1a9d844cf95c4b3e9e83920a0061f578",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 10000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 10000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b5aa065e9f5947388c9d3b3b865d1310"
          }
        },
        "6d9cde79a0c64874a77691743bca10be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_09bd4cf6d47549b4931138ac9c632f87",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 10000/10000 [00:11&lt;00:00, 893.95it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_80968687345f4b079fdbd4ebe79de5ee"
          }
        },
        "1a9d844cf95c4b3e9e83920a0061f578": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b5aa065e9f5947388c9d3b3b865d1310": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "09bd4cf6d47549b4931138ac9c632f87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "80968687345f4b079fdbd4ebe79de5ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzR6cZvYkyl6",
        "colab_type": "text"
      },
      "source": [
        "# Assignment 3\n",
        "\n",
        "**Submission deadline: last lab session before or on Thursday, 02.04.2020**\n",
        "\n",
        "**Points: 12 + 4 bonus points**\n",
        "\n",
        "## Submission instructions\n",
        "**To ease grading, please do not remove the TODO lines, put your code below them!**\n",
        "\n",
        "The class is held remotely. To sumbmit your solutions please save the notebook to your Google Drive, then:\n",
        "1. Rename it it to: Assignment3_Surname_FirstName\n",
        "2. Rerun the whole notebook `Runtime -> Restart and run all`\n",
        "3. Make a pinned revision `File->Save and pin revision`\n",
        "4. Share the notebook and paste the link into an appropriate SKOS assignment\n",
        "\n",
        "We will use the commenting system and video conferences to check and discuss the solutions.\n",
        "\n",
        "As always, please submit corrections using GitHub's Pull Requests."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEUPZksWm9YU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "039umgT_lsH2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "from tqdm import trange\n",
        "\n",
        "import PIL\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.datasets\n",
        "from torchvision import transforms\n",
        "\n",
        "from IPython.display import clear_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNfw6pY9sRJe",
        "colab_type": "text"
      },
      "source": [
        "# Helper code\n",
        "\n",
        "The code in this section handles data loading, result validation and plotting. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPOMFqLZsfuj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_error_rate(model, data_loader, device='cpu'):\n",
        "    \"\"\"Evaluate model on all samples from the data loader.\n",
        "    \"\"\"\n",
        "    # Put the model in eval mode, and move to the evaluation device.\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "    if isinstance(data_loader, InMemDataLoader):\n",
        "        data_loader.to(device)\n",
        "    \n",
        "    num_errs = 0.0\n",
        "    num_examples = 0\n",
        "    # we don't need gradient during eval!\n",
        "    with torch.no_grad():\n",
        "        for x, y in data_loader:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            outputs = model.forward(x)\n",
        "            _, predictions = outputs.data.max(dim=1)\n",
        "            num_errs += (predictions != y.data).sum().item()\n",
        "            num_examples += x.size(0)\n",
        "    \n",
        "\n",
        "    #model back to training with dropouts\n",
        "    model.train(True)\n",
        "    return num_errs / num_examples\n",
        "\n",
        "def plot_history(history):\n",
        "    \"\"\"Helper to plot the trainig progress over time.\"\"\"\n",
        "    plt.figure(figsize=(16, 4))\n",
        "    plt.subplot(1,2,1)\n",
        "    train_loss = np.array(history['train_losses'])\n",
        "    plt.semilogy(np.arange(train_loss.shape[0]), train_loss, label='batch train loss')\n",
        "    plt.legend()\n",
        "        \n",
        "    plt.subplot(1,2,2)\n",
        "    train_errs = np.array(history['train_errs'])\n",
        "    plt.plot(np.arange(train_errs.shape[0]), train_errs, label='batch train error rate')\n",
        "    val_errs = np.array(history['val_errs'])\n",
        "    plt.plot(val_errs[:,0], val_errs[:,1], label='validation error rate', color='r')\n",
        "    plt.ylim(0, 0.20)\n",
        "    plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OT6R09JnnYs9",
        "colab_type": "text"
      },
      "source": [
        "## Data preparation\n",
        "\n",
        "We will download the MNIST data using `torchvision`, then use a fast in-memory loader."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPh9uR8ZorL7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class InMemDataLoader(object):\n",
        "    \"\"\"\n",
        "    A data loader that keeps all data in CPU or GPU memory.\n",
        "    \"\"\"\n",
        "    __initialized = False\n",
        "    def __init__(self, dataset, batch_size=1, shuffle=False, sampler=None,\n",
        "                 batch_sampler=None, drop_last=False):\n",
        "        \"\"\"A torch dataloader that fetches data from memory.\"\"\"\n",
        "        batches = []\n",
        "        for i in tqdm(range(len(dataset))):\n",
        "            batch = [torch.tensor(t) for t in dataset[i]]\n",
        "            batches.append(batch)\n",
        "        tensors = [\n",
        "            torch.stack(ts) for ts in zip(*batches)\n",
        "        ]\n",
        "        dataset = torch.utils.data.TensorDataset(*tensors)\n",
        "        self.dataset = dataset\n",
        "        self.batch_size = batch_size\n",
        "        self.drop_last = drop_last\n",
        "        \n",
        "        if batch_sampler is not None:\n",
        "            if batch_size > 1 or shuffle or sampler is not None or drop_last:\n",
        "                raise ValueError('batch_sampler option is mutually exclusive '\n",
        "                                 'with batch_size, shuffle, sampler, and '\n",
        "                                 'drop_last')\n",
        "            self.batch_size = None\n",
        "            self.drop_last = None\n",
        "\n",
        "        if sampler is not None and shuffle:\n",
        "            raise ValueError('sampler option is mutually exclusive with '\n",
        "                             'shuffle')\n",
        "            \n",
        "        if batch_sampler is None:\n",
        "            if sampler is None:\n",
        "                if shuffle:\n",
        "                    sampler = torch.utils.data.RandomSampler(dataset)\n",
        "                else:\n",
        "                    sampler = torch.utils.data.SequentialSampler(dataset)\n",
        "            batch_sampler = torch.utils.data.BatchSampler(sampler, batch_size, drop_last)\n",
        "\n",
        "        self.sampler = sampler\n",
        "        self.batch_sampler = batch_sampler\n",
        "        self.__initialized = True\n",
        "    \n",
        "    def __setattr__(self, attr, val):\n",
        "        if self.__initialized and attr in ('batch_size', 'sampler', 'drop_last'):\n",
        "            raise ValueError('{} attribute should not be set after {} is '\n",
        "                             'initialized'.format(attr, self.__class__.__name__))\n",
        "\n",
        "        super(InMemDataLoader, self).__setattr__(attr, val)\n",
        "\n",
        "    def __iter__(self):\n",
        "        for batch_indices in self.batch_sampler:\n",
        "            yield self.dataset[batch_indices]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.batch_sampler)\n",
        "    \n",
        "    def to(self, device):\n",
        "        self.dataset.tensors = tuple(t.to(device) for t in self.dataset.tensors)\n",
        "        return self"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDM2KTPQm8V3",
        "colab_type": "code",
        "outputId": "a44f1109-6458-4d51-8dd7-64d45bc432df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218,
          "referenced_widgets": [
            "0587df20b83a4303a0b2c427d2221889",
            "d4d7733316b346e18b6568b8291c02d0",
            "c3f494e962c34eba86377798bf21b0eb",
            "4a153190700f49bdb2bd96d0fbfca8f1",
            "616607599e12427faf70f8f824ab0257",
            "2c5c8ceaa6024424babbbc5671eaf35a",
            "b12423ee45784081b87faf702761d9f6",
            "0444d22486c54fcb96a42562c916d2a0",
            "573f5aa4ab43432abbde5b60b6332d2f",
            "df2797dde693461a90c47657f9b4c2d1",
            "c67a0e3b38c643648a2b6d6f88858d94",
            "2d38b1f1ca534b238ecdbef83bd16cb1",
            "04404a275afe45d9afab96dd7f9363e8",
            "a1feea427fe4450da5014fff389b689e",
            "8fbb872595c5430295006133742d40f0",
            "82e747ff73bc4e1ea5b1213f6c9e53fc",
            "dfa4db0de0f64d61ba19ef55d2d18907",
            "e0f78ce31cd846fdb5f0d447de4e8381",
            "a482d16528e3491ea30f43a2e2304005",
            "6d9cde79a0c64874a77691743bca10be",
            "1a9d844cf95c4b3e9e83920a0061f578",
            "b5aa065e9f5947388c9d3b3b865d1310",
            "09bd4cf6d47549b4931138ac9c632f87",
            "80968687345f4b079fdbd4ebe79de5ee"
          ]
        }
      },
      "source": [
        "# Load the data\n",
        "\n",
        "batch_size = 128\n",
        "data_path = './data'\n",
        "\n",
        "transform = torchvision.transforms.Compose(\n",
        "    [torchvision.transforms.ToTensor(),\n",
        "     torchvision.transforms.Normalize((0.1307,), (0.3081,)),\n",
        "    ])\n",
        "\n",
        "_test = torchvision.datasets.MNIST(\n",
        "    data_path, train=False, download=True, transform=transform)\n",
        "\n",
        "# Load training data, split into train and valid sets\n",
        "_train = torchvision.datasets.MNIST(\n",
        "    data_path, train=True, download=True, transform=transform)\n",
        "_train.data = _train.data[:50000]\n",
        "_train.targets = _train.targets[:50000]\n",
        "\n",
        "_valid = torchvision.datasets.MNIST(\n",
        "    data_path, train=True, download=True, transform=transform)\n",
        "_valid.data = _valid.data[50000:]\n",
        "_valid.targets = _valid.targets[50000:]\n",
        "\n",
        "mnist_loaders = {\n",
        "    'train': InMemDataLoader(\n",
        "        _train, batch_size=batch_size, shuffle=True),\n",
        "    'valid': InMemDataLoader(\n",
        "        _valid, batch_size=batch_size, shuffle=False),\n",
        "    'test': InMemDataLoader(\n",
        "        _test, batch_size=batch_size, shuffle=False)}"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0587df20b83a4303a0b2c427d2221889",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=50000), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "573f5aa4ab43432abbde5b60b6332d2f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=10000), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dfa4db0de0f64d61ba19ef55d2d18907",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=10000), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRYr7XmnnGO_",
        "colab_type": "text"
      },
      "source": [
        "# SGD implementation\n",
        "\n",
        "We provide below a scaffolding for SGD. You will need to fill the TODOs while solving the assignments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WY1xG-cqnRoE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def SGD(model, data_loaders, \n",
        "        alpha=1e-4, alpha_decay=1, epsilon=0.0, decay=0.0,\n",
        "        num_epochs=1, max_num_epochs=np.nan, patience_expansion=1.5,\n",
        "        log_every=100, device='cpu', verbose=True):\n",
        "    \n",
        "    # Put the model in train mode, and move to the evaluation device.\n",
        "    model.train()\n",
        "    model.to(device)\n",
        "    for data_loader in data_loaders.values():\n",
        "        if isinstance(data_loader, InMemDataLoader):\n",
        "            data_loader.to(device)\n",
        "    \n",
        "    #\n",
        "    # TODO: Initialize momentum variables\n",
        "    # Hint: You need one velocity matrix for each parameter\n",
        "    #\n",
        "    velocities = [torch.zeros(p.shape, device=device) for p in model.parameters()]\n",
        "    \n",
        "    iter_ = 0\n",
        "    epoch = 0\n",
        "    best_params = None\n",
        "    best_val_err = np.inf\n",
        "    history = {'train_losses': [], 'train_errs': [], 'val_errs': []}\n",
        "    if verbose:\n",
        "        print('Training the model!')\n",
        "        print('Interrupt at any time to evaluate the best validation model so far.')\n",
        "    try:\n",
        "        tstart = time.time()\n",
        "        siter = iter_\n",
        "        while epoch < num_epochs:\n",
        "            model.train()\n",
        "            epoch += 1\n",
        "            if epoch > max_num_epochs:\n",
        "                break\n",
        "            #\n",
        "            # TODO: You can implement learning rate control here (it is updated\n",
        "            # once per epoch), or below in the loop over minibatches.\n",
        "            #\n",
        "            # implemented below, we multiply it every 1000 iterations by constant\n",
        "                        \n",
        "            for x, y in data_loaders['train']:\n",
        "                x = x.to(device)\n",
        "                y = y.to(device)\n",
        "                iter_ += 1\n",
        "\n",
        "                if iter_ % 1000 == 0:\n",
        "                    alpha *= alpha_decay\n",
        "\n",
        "                # This calls the `forward` function: https://pytorch.org/tutorials/beginner/examples_nn/two_layer_net_module.html\n",
        "                out = model(x)\n",
        "                loss = model.loss(out, y)\n",
        "                loss.backward()\n",
        "                _, predictions = out.max(dim=1)\n",
        "                batch_err_rate = (predictions != y).sum().item() / out.size(0)\n",
        "\n",
        "                history['train_losses'].append(loss.item())\n",
        "                history['train_errs'].append(batch_err_rate)\n",
        "                \n",
        "                # disable gradient computations - we do not want torch to\n",
        "                # backpropagate through the gradient application!\n",
        "                with torch.no_grad():\n",
        "                    for (name, p), v in zip(model.named_parameters(),\n",
        "                                            velocities):\n",
        "                        if 'weight' in name:\n",
        "                            #\n",
        "                            # TODO: Implement weight decay (L2 regularization\n",
        "                            # on weights by changing the gradients\n",
        "                            p.grad += 2*decay * p\n",
        "\n",
        "                        #\n",
        "                        # TODO: Implement a learning rate schedule\n",
        "                        # Hint: You can use the iteration or epoch counters\n",
        "                        # \n",
        "\n",
        "                        #\n",
        "                        # TODO: If needed, implement here a momentum schedule\n",
        "                        # epsilon = TODO\n",
        "                        #\n",
        "\n",
        "                        #\n",
        "                        # TODO: Implement velocity updates for momentum\n",
        "                        # please make sure to modify the contents of v, not the v pointer!!!\n",
        "                        #\n",
        "                        v[:] = epsilon*v + p.grad\n",
        "\n",
        "                        #\n",
        "                        # TODO: Set a more sensible learning rule here,\n",
        "                        #       using your learning rate schedule and momentum\n",
        "                        # \n",
        "                        # p -= alpha * p.grad\n",
        "                        p -= alpha * v\n",
        "                        \n",
        "                        # Zero gradients for the next iteration\n",
        "                        p.grad.zero_()\n",
        "\n",
        "                if iter_ % log_every == 0:\n",
        "                    num_iter = iter_ - siter + 1\n",
        "                    if verbose:\n",
        "                        print(\"Minibatch {0: >6}  | loss {1: >5.2f} | err rate {2: >5.2f}%, steps/s {3: >5.2f}\" \\\n",
        "                            .format(iter_, loss.item(), batch_err_rate * 100.0, num_iter / (time.time() - tstart)))\n",
        "                    tstart = time.time()\n",
        "            \n",
        "\n",
        "            val_err_rate = compute_error_rate(model, data_loaders['valid'], device)\n",
        "            history['val_errs'].append((iter_, val_err_rate))\n",
        "            \n",
        "            if val_err_rate < best_val_err:\n",
        "                # Adjust num of epochs\n",
        "                num_epochs = int(np.maximum(num_epochs, epoch * patience_expansion + 1))\n",
        "                best_epoch = epoch\n",
        "                best_val_err = val_err_rate\n",
        "                best_params = [p.detach().cpu() for p in model.parameters()]\n",
        "            \n",
        "            if verbose:\n",
        "                clear_output(True)\n",
        "                m = \"After epoch {0: >2} | valid err rate: {1: >5.2f}% | doing {2: >3} epochs\" \\\n",
        "                    .format(epoch, val_err_rate * 100.0, num_epochs)\n",
        "                print('{0}\\n{1}\\n{0}'.format('-' * len(m), m))\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        pass\n",
        "\n",
        "    if verbose:\n",
        "        if best_params is not None:\n",
        "            print(\"\\nLoading best params on validation set (epoch %d)\\n\" %(best_epoch))\n",
        "            with torch.no_grad():\n",
        "                for param, best_param in zip(model.parameters(), best_params):\n",
        "                    param[...] = best_param\n",
        "        plot_history(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGjN2ezZ3sQR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(Model, self).__init__()\n",
        "        self.layers = nn.Sequential(*args, **kwargs)\n",
        "\n",
        "    def forward(self, X):\n",
        "        X = X.view(X.size(0), -1)\n",
        "        return self.layers.forward(X)\n",
        "    \n",
        "    def loss(self, Out, Targets):\n",
        "        return F.cross_entropy(Out, Targets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1lz2PXs4C0Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_mnist(model, alpha, alpha_decay, epsilon, decay, data_loader=mnist_loaders, max_num_epochs=30, device='cuda',\n",
        "               reruns=1, verbose=False, with_tqdm=True):\n",
        "    if with_tqdm:\n",
        "        range_ = trange(reruns, position=0, leave=True)\n",
        "    else:\n",
        "        range_ = range(reruns)\n",
        "\n",
        "    history = []\n",
        "    for _ in range_:\n",
        "        with torch.no_grad():\n",
        "            # Initialize parameters\n",
        "            for name, p in model.named_parameters():\n",
        "                # print(p)\n",
        "                if 'weight' in name:\n",
        "                    torch.nn.init.xavier_normal_(p)\n",
        "                    # p.normal_(0, 0.5)\n",
        "                elif 'bias' in name:\n",
        "                    p.zero_()\n",
        "                else:\n",
        "                    raise ValueError('Unknown parameter name \"%s\"' % name)\n",
        "                    \n",
        "        # On GPU enabled devices set device='cuda' else set device='cpu'\n",
        "        t_start = time.time()\n",
        "        SGD(model, data_loader, alpha=alpha, alpha_decay=alpha_decay, epsilon=epsilon, decay=decay, \n",
        "            max_num_epochs=max_num_epochs, device=device, verbose=verbose)\n",
        "\n",
        "\n",
        "        test_err_rate = compute_error_rate(model, data_loader['test'])\n",
        "        history.append(test_err_rate)\n",
        "\n",
        "        if verbose:\n",
        "            m = (f\"Test error rate: {test_err_rate * 100.0:.3f}%, \"\n",
        "                f\"training took {time.time() - t_start:.0f}s.\")\n",
        "            print('{0}\\n{1}\\n{0}'.format('-' * len(m), m))\n",
        "    return np.array(history) * 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFruXwnAxCjb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reruns = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "a0fc95d2-5b9b-4ae9-a1d1-d39b0de5c395",
        "id": "xR300O-BzbGJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "model = Model(\n",
        "    nn.Linear(28*28, 10)\n",
        "    )\n",
        "\n",
        "history = test_mnist(model, alpha=0.01, alpha_decay=0.9, epsilon=0.9, decay=0.01, reruns=reruns)\n",
        "print(f'From {reruns} reruns.\\nMean err_rate: {history.mean()}, best: {history.min()}')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:25<00:00,  2.55s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "From 10 reruns.\n",
            "Mean err_rate: 8.746, best: 8.309999999999999\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQa69LGTaiym",
        "colab_type": "text"
      },
      "source": [
        "# Problem 1: Stochastic Gradient Descent [3p]\n",
        "Implement the following additions to the SGD code provided above:\n",
        "  1. **[1p]** momentum\n",
        "  2. **[1p]** learning rate schedule\n",
        "  3. **[1p]** weight decay, in which we additionally minimize for each weight matrix (but typically not the bias) the sum of its elements squared. One way to implement it is to use function `model.named_parameters` and select all parameters whose names contain \"`weight`\" rather than \"`bias`\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsLt4dGsaosv",
        "colab_type": "text"
      },
      "source": [
        "# Problem 2: Tuning the Network for MNIST [4p]\n",
        "\n",
        "Tune the following network to reach **validation error rate below 1.9%**.\n",
        "This should result in a **test error rate below 2%**. To\n",
        "tune the network you will need to:\n",
        "1. Choose the number of layers (more than 1, less than 5);\n",
        "2. Choose the number of neurons in each layer (more than 100,\n",
        "    less than 5000);\n",
        "3. Pick proper weight initialization;\n",
        "4. Pick proper learning rate schedule (need to decay over time,\n",
        "    good range to check on MNIST is about 1e-2 ... 1e-1 at the beginning and\n",
        "    half of that after 10000 batches);\n",
        "5. Pick a momentum constant (probably a constant one will be OK).\n",
        "\n",
        "\n",
        "Please note: there are many hyperparameter settings that give the desired answer, some may require tuning all hyperparameters, some only a few."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBXC_SJvv3Lx",
        "colab_type": "code",
        "outputId": "44b5adba-c5d0-4d01-e0af-028d391b2b6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "model = Model(\n",
        "    nn.Linear(28*28, 800),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(800, 400),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(400, 10)\n",
        "    )\n",
        "\n",
        "history = test_mnist(model, alpha=0.05, alpha_decay=0.9, epsilon=0.5, decay=0.001, reruns=reruns)\n",
        "print(f'From {reruns} reruns.\\nMean err_rate: {history.mean()}, best: {history.min()}')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [02:58<00:00, 17.82s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "From 10 reruns.\n",
            "Mean err_rate: 1.9040000000000004, best: 1.79\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrUQloaln1UA",
        "colab_type": "text"
      },
      "source": [
        "# Problem 3: Convolutional Network [2p]\n",
        "\n",
        "Use convolutional and max-pooling layers (`Conv2d`, `Max_pool2d` or their functional variants) and (without dropout) get a test error rate below 1.5%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMn1cFJT4obv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, with_dropout=False):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 15, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(15, 30, kernel_size=5)\n",
        "        self.fc1 = nn.Linear(480, 200)\n",
        "        self.fc2 = nn.Linear(200, 10)\n",
        "        self.with_dropout = with_dropout\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(self.conv1(x), 2)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(self.conv2(x), 2)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = x.view(-1, 480)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        if self.with_dropout:\n",
        "            x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x)\n",
        "    \n",
        "    def loss(self, Out, Targets):\n",
        "        return F.cross_entropy(Out, Targets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYArLym488Ot",
        "colab_type": "code",
        "outputId": "8934839a-29c1-43a1-b046-205207db1bf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "model = ConvNet()\n",
        "\n",
        "history = test_mnist(model, alpha=0.05, alpha_decay=0.9, epsilon=0.5, decay=0.001, reruns=reruns)\n",
        "print(f'From {reruns} reruns.\\nMean err_rate: {history.mean()}, best: {history.min()}')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/10 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "100%|██████████| 10/10 [05:40<00:00, 34.04s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "From 10 reruns.\n",
            "Mean err_rate: 1.082, best: 0.77\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9DaWUy_atrn",
        "colab_type": "text"
      },
      "source": [
        "# Problem 4: Dropout [2p]\n",
        "\n",
        "Learn about dropout:\n",
        "\n",
        "- implement a **dropout** layer \n",
        "- or use `nn.Dropout` (then the exercise is worth 1.5 points)\n",
        "\n",
        "and try to train a\n",
        "network getting below 1.5% test error rates with dropout, but no convolutions, or below 1% when dropout is used jointly with convolutions!\n",
        "\n",
        "Remember to turn off dropout during testing, using `model.train()` and `model.eval()`!\n",
        "\n",
        "Hint: Use [torch.nn.functional.dropout](http://pytorch.org/docs/master/nn.html#torch.nn.functional.dropout).\n",
        "\n",
        "Details: http://arxiv.org/pdf/1207.0580.pdf."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbcRnjlEBffO",
        "colab_type": "code",
        "outputId": "a85ddfa8-68e3-43b7-a179-63e2c85eef32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "model = ConvNet(with_dropout=True)\n",
        "\n",
        "history = test_mnist(model, alpha=0.05, alpha_decay=0.95, epsilon=0.5, decay=0.001, reruns=reruns)\n",
        "print(f'From {reruns} reruns.\\nMean err_rate: {history.mean()}, best: {history.min()}')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/10 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "100%|██████████| 10/10 [06:52<00:00, 41.26s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "From 10 reruns.\n",
            "Mean err_rate: 0.8109999999999999, best: 0.6799999999999999\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mB3T_HuYawyQ",
        "colab_type": "text"
      },
      "source": [
        "# Problem 5: Data Augmentation [1p]\n",
        "\n",
        "Apply data augmentation methods (e.g. rotations, noise, crops) when training networks on MNIST, to significantly reduce test error rate for your network. You can use functions from the [torchvision.transforms](http://pytorch.org/docs/master/torchvision/transforms.html) module.\n",
        "\n",
        "Please note: when using random transfromations during training, use a data loader that re-computes them for each training minibatch. The `InMemoryDataloader` assumes that the transformations are deterministic and applies them only once."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yv3XkbJ4JHs8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "data_path = './data'\n",
        "\n",
        "transform1 = torchvision.transforms.Compose(\n",
        "    [torchvision.transforms.ToTensor(),\n",
        "     torchvision.transforms.Normalize((0.1307,), (0.3081,)),\n",
        "    ])\n",
        "\n",
        "transform2 = transforms.Compose([\n",
        "    transforms.RandomApply([\n",
        "        transforms.RandomAffine(degrees=30, resample=PIL.Image.NEAREST),\n",
        "        transforms.ColorJitter(brightness=0.3, contrast=0.3),\n",
        "        transforms.Compose([\n",
        "            transforms.RandomCrop(24, pad_if_needed=True),\n",
        "            transforms.Pad(2),\n",
        "        ])         \n",
        "    ],\n",
        "    0.7),\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize((0.1307,), (0.3081,)),\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wT5ogPsNueEG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_test = torchvision.datasets.MNIST(\n",
        "    data_path, train=False, download=True, transform=transform1)\n",
        "\n",
        "# Load training data, split into train and valid sets\n",
        "_train = torchvision.datasets.MNIST(\n",
        "    data_path, train=True, download=True, transform=transform2)\n",
        "_train.data = _train.data[:50000]\n",
        "_train.targets = _train.targets[:50000]\n",
        "\n",
        "_valid = torchvision.datasets.MNIST(\n",
        "    data_path, train=True, download=True, transform=transform1)\n",
        "_valid.data = _valid.data[50000:]\n",
        "_valid.targets = _valid.targets[50000:]\n",
        "\n",
        "mnist_loaders_augmented = {\n",
        "    'train': torch.utils.data.DataLoader(\n",
        "        _train, batch_size=batch_size, shuffle=True),\n",
        "    'valid': torch.utils.data.DataLoader(\n",
        "        _valid, batch_size=batch_size, shuffle=False),\n",
        "    'test': torch.utils.data.DataLoader(\n",
        "        _test, batch_size=batch_size, shuffle=False)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EC-76rP5I5o-",
        "colab_type": "text"
      },
      "source": [
        "#### Testing for model from problem 2 which had about 1.9% error rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IInZTSJ1fyRv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "d2bfac2d-1ed1-49e9-803a-f4f31c28452d"
      },
      "source": [
        "model = Model(\n",
        "    nn.Linear(28*28, 800),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(800, 400),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(400, 10)\n",
        "    )\n",
        "\n",
        "\n",
        "history = test_mnist(model, alpha=0.05, alpha_decay=0.9, epsilon=0.5, decay=0.001, data_loader=mnist_loaders_augmented,\n",
        "                     reruns=reruns)\n",
        "print(f'From {reruns} reruns.\\nMean err_rate: {history.mean()}, best: {history.min()}')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [1:14:11<00:00, 445.17s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "From 10 reruns.\n",
            "Mean err_rate: 1.372, best: 1.23\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Af7itFE7a0eY",
        "colab_type": "text"
      },
      "source": [
        "# Problem 6: Batch Normalization [1p bonus]\n",
        "\n",
        "[Batch Normalization](https://arxiv.org/abs/1502.03167) helps training neural networks because it [normalizes layer activation magnitudes](https://papers.nips.cc/paper/7515-how-does-batch-normalization-help-optimization.pdf). It typically allows to train networks faster and/or with higher learning rates, lessens the importance\n",
        "of initialization and might eliminate the need for Dropout.\n",
        "\n",
        "Implement Batch Normalization and compare with regular training of MNIST models.\n",
        "\n",
        "Remember to use the batch statistics during model training and to use an average of training batch statistics during model evaluation. For details please consult the paper."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CD1Ke8R4a1-Q",
        "colab_type": "text"
      },
      "source": [
        "# Problem 7: Norm Constraints [1p bonus]\n",
        "\n",
        "Implement norm constraints, i.e. instead of weight decay, that tries to set \n",
        "all weights to small values, apply a limit on the total\n",
        "norm of connections incoming to a neuron. In our case, this\n",
        "corresponds to clipping the norm of *rows* of weight\n",
        "matrices. An easy way of implementing it is to make a gradient\n",
        "step, then look at the norm of rows and scale down those that are\n",
        "over the threshold (this technique is called \"projected gradient descent\").\n",
        "\n",
        "Please consult the Dropout paper (http://arxiv.org/pdf/1207.0580.pdf) for details."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CL3_e1xCa4YG",
        "colab_type": "text"
      },
      "source": [
        "# Problem 8: Polyak Averaging [1p bonus]\n",
        "\n",
        "Implement Polyak averaging. For each parameter $\\theta$\n",
        "keep a separate, exponentially decayed average of the past values\n",
        "$$\n",
        "\\bar{\\theta}_n = \\alpha_p\\bar{\\theta}_{n-1} + (1-\\alpha_p)\\theta_n.\n",
        "$$\n",
        "Use that average when evaluating the model on the test set.\n",
        "Validate the approach by training a model on the MNIST dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7LoH9DIa88J",
        "colab_type": "text"
      },
      "source": [
        "# Problem 9: Hyperparameter tuner [1p bonus]\n",
        "\n",
        "Implement a hyper-parameter tuner able to optimize the learing rate schedule, number of neurons and similar hyperparameters. For start, use random search (please see http://jmlr.csail.mit.edu/papers/volume13/bergstra12a/bergstra12a.pdf and especially Fig 1. for intuitions on why random search is better than grid search). It may be a good idea to use a fixed maximum number of epochs (or training time) for each optimization trial to prevent selecting hyperparameters that yield slowly converging solutions. A good result will be a set of hyperparameters that reach on MNIST solutions with test errors less than $1.3\\%$ in no more than 50 epochs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jyEkvsqo2bx",
        "colab_type": "text"
      },
      "source": [
        "# Problem 10: Other tricks [1-many bonus pounts]\n",
        "\n",
        "The neural network literature is ful of trickss for training neural networks. Find some and implement them. Please note: the number of points depends on the hardness of the extension you want to implement. If in doubt, consult the TA beforehand"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OB1BwNdrpLSS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}